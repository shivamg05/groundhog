{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-YNCGwPHuXJr",
        "outputId": "301659d6-d0ef-42b8-e8e3-435d0c6cca8d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (4.4.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (4.14.3)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (12.0.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.57.3)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (1.12.0)\n",
            "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.10/dist-packages (0.48.2)\n",
            "Requirement already satisfied: peft in /usr/local/lib/python3.10/dist-packages (0.18.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.24.1)\n",
            "Requirement already satisfied: pyarrow>=21.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (22.0.0)\n",
            "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.4.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.3.3)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.5)\n",
            "Requirement already satisfied: httpx<1.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.28.1)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.19 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.18)\n",
            "Requirement already satisfied: fsspec<=2025.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2025.10.0)\n",
            "Requirement already satisfied: huggingface-hub<2.0,>=0.25.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.36.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: soupsieve>=1.6.1 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4) (2.5)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4) (4.15.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2025.11.3)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.7.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.6)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.9.1)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (3.13.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1.0.0->datasets) (4.0.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1.0.0->datasets) (2022.12.7)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1.0.0->datasets) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx<1.0.0->datasets) (3.4)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (1.2.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.1.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (1.26.13)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->accelerate) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->accelerate) (3.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->accelerate) (3.1.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->accelerate) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->accelerate) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->accelerate) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->accelerate) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->accelerate) (12.8.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->accelerate) (11.3.3.83)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->accelerate) (10.3.9.90)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->accelerate) (11.7.3.90)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->accelerate) (12.5.8.93)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->accelerate) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->accelerate) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->accelerate) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->accelerate) (12.8.90)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->accelerate) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->accelerate) (1.13.1.3)\n",
            "Requirement already satisfied: triton==3.5.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->accelerate) (3.5.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (5.0.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (23.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.22.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1.0.0->datasets) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1.0.0->datasets) (1.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.0.0->accelerate) (2.1.2)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install -U datasets beautifulsoup4 pillow transformers accelerate bitsandbytes transformers peft"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OKRsXY0FZKwD"
      },
      "source": [
        "# Part 1: Preprocess Mind2Web"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1wujSI9fzuqQ",
        "outputId": "163e1de0-1dd7-4910-a579-aec72f56c810"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hugging Face Cache is now set to: /workspace/hf_cache\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# Force Hugging Face to download models to the large /workspace volume\n",
        "# instead of the tiny system disk.\n",
        "os.environ[\"HF_HOME\"] = \"/workspace/hf_cache\"\n",
        "\n",
        "print(f\"Hugging Face Cache is now set to: {os.environ['HF_HOME']}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "08a2ee200f1a4ff2bd457c3b39214de0",
            "6b0e214f070d4289b86f78c74d429dfa",
            "33e4c16fb7014c70a8116928465fdf2d",
            "3789283a2e9147e3ad478699c98e31e6",
            "90c18d1a9c344ee28715cb02f93ce3d8",
            "9da29813b9e4417db6227244ccd79ca0",
            "f956d0508ebb47adb7c5a68e5919af00",
            "a99a0a2b8fa749beb1e7d4b1b20cd810",
            "3bc89500c83341a09d26667c80a4dd79",
            "14fd91cf7e8844548942bce8ae07fd25",
            "237c33efcc354dddabe7464b5f68f616",
            "66513eb1d1754e7a84a42383bcc0ab92"
          ]
        },
        "id": "mPdS75wXmrdH",
        "outputId": "7769be11-9e7f-486c-c92d-832c3bd77413"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "66513eb1d1754e7a84a42383bcc0ab92",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Resolving data files:   0%|          | 0/27 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import datasets\n",
        "from PIL import Image\n",
        "\n",
        "# Load the correct, flattened multimodal dataset from Hugging Face\n",
        "# Using streaming=True is still recommended to save disk space\n",
        "multimodal_dataset = datasets.load_dataset(\"osunlp/Multimodal-Mind2Web\", split=\"train\", streaming=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uW20mHKBy9FZ",
        "outputId": "e36baa74-d56d-4f04-95ec-e1d921841b2b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- First Training Example (Single Action) ---\n",
            "Goal: rent a car in Brooklyn - Central, NY on from April 9 to April 15.\n",
            "\n",
            "Target Action Representation: [heading]  CAR -> CLICK\n",
            "\n",
            "Cleaned HTML Snippet (first 500 chars):\n",
            "<html backend_node_id=\"208\">\n",
            "  <body backend_node_id=\"500\">\n",
            "    <div backend_node_id=\"1054\">\n",
            "      <div backend_node_id=\"1055\">\n",
            "        <div backend_node_id=\"1056\">\n",
            "          <div backend_node_id=\"1057\">\n",
            "            <div backend_node_id=\"1060\">\n",
            "              <div backend_node_id=\"1064\">\n",
            "                <h1 backend_node_id=\"1065\">\n",
            "                  <text backend_node_id=\"1066\">Welcome to United.com</text>\n",
            "                </h1>\n",
            "                <a backend_node_id=\"1067\">\n",
            "                  <text bac\n",
            "\n",
            "Screenshot object:\n",
            "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1280x5429 at 0x7AAAD53ABF70>\n",
            "Image mode: RGB, Image size: (1280, 5429)\n"
          ]
        }
      ],
      "source": [
        "import datasets\n",
        "from PIL import Image\n",
        "\n",
        "# Get the first training example (which is a single action) to inspect it\n",
        "first_example = next(iter(multimodal_dataset))\n",
        "\n",
        "# --- Print out the key fields to see the new data structure ---\n",
        "print(\"--- First Training Example (Single Action) ---\")\n",
        "print(f\"Goal: {first_example['confirmed_task']}\")\n",
        "\n",
        "# This is the specific action for this row\n",
        "print(f\"\\nTarget Action Representation: {first_example['target_action_reprs']}\")\n",
        "\n",
        "# The HTML is now a direct field of the example\n",
        "print(\"\\nCleaned HTML Snippet (first 500 chars):\")\n",
        "print(first_example['cleaned_html'][:500])\n",
        "\n",
        "# The 'screenshot' field will be loaded as a Pillow Image object directly\n",
        "print(\"\\nScreenshot object:\")\n",
        "screenshot_image = first_example['screenshot']\n",
        "print(screenshot_image)\n",
        "print(f\"Image mode: {screenshot_image.mode}, Image size: {screenshot_image.size}\")\n",
        "\n",
        "# You can display the image in Colab by having `screenshot_image` as the last line\n",
        "# screenshot_image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MTSV8aRM2AJz"
      },
      "outputs": [],
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import json\n",
        "import re"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data ended up being processed in groundhog-data-processing.ipynb"
      ],
      "metadata": {
        "id": "nsF5xfwv1sIh"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q_I0EVlqZWWI"
      },
      "source": [
        "# Part 2: Load Preprocessed Mind2Web"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UmVRRP0BYIAh"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "# This command will initiate the mounting process.\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4InuIq5PYtYt",
        "outputId": "8398a0c7-281b-4b47-c4a7-a9eed278c7e8",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Checking the first 3 lines of the file from Google Drive ---\n",
            "\n",
            "--- Example 1 ---\n",
            "Prompt Snippet:\n",
            "You are a web agent. Analyze the screenshot and the list of elements.\n",
            "The element list is formatted as: [ID] <Tag> Text (Attributes).\n",
            "If the target element is not in the list, select ID 0.\n",
            "Your task is to select the correct Element ID to perform the action on.\n",
            "\n",
            "TASK: rent a car in Brooklyn - Central, NY on from April 9 to April 15.\n",
            "\n",
            "ELEMENTS:\n",
            "[0] <option> Target element is not in this list\n",
            "[-] <h1> Welcome to United.com\n",
            "[1067] <a> Skip to book\n",
            "[1085] <li> English - United States$\n",
            "[1088] <button> English - United States$\n",
            "[1096] <button>\n",
            "[1100] <li> Search\n",
            "[1101] <a> Search\n",
            "[1112] <button> Hi, James 0 miles\n",
            "[1129] <button>\n",
            "[1133] <li> Menu\n",
            "[1134] <button> Menu\n",
            "[1145] <a> BOOK (role='tab')\n",
            "[1148] <a> MY TRIPS (role='tab')\n",
            "[1151] <a> TRAVEL INFO (role='tab')\n",
            "[1154] <a> MILEAGEPLUS PROGRAM (role='tab')\n",
            "[1157] <a> DEALS (role='tab')\n",
            "[1163] <button>\n",
            "[1168] <button>\n",
            "[1173] <button>\n",
            "[1178] <button>\n",
            "[1183] <button>\n",
            "[1186] <a> Help\n",
            "[1204] <li> Book (role='tab', name='travelTab')\n",
            "[1210] <li> Flight status (role='tab', name='statusTab')\n",
            "[1216] <li> Check-in (role='tab')\n",
            "[1222] <li> My trips (role='tab')\n",
            "[1242] <li> Flight (role='tab')\n",
            "[1246] <li> Hotel (role='tab')\n",
            "[1250] <li> Car (role='tab')\n",
            "[1253] <li> Packages (role='tab')\n",
            "[1257] <li> Cruise\n",
            "[1258] <a> Cruise\n",
            "[1266] <label> Roundtrip\n",
            "[1269] <input> (type='radio', value='on')\n",
            "[1272] <label> One-way\n",
            "[1275] <input> (type='radio', value='on')\n",
            "[1279] <input> (type='checkbox', name='AwardTravel', value='on')\n",
            "[1280] <label> Book with miles\n",
            "[1286] <input> (type='checkbox', name='Flexible', value='on')\n",
            "[1287] <label> Flexible dates\n",
            "[1300] <input> (role='combobox', value='Pune PNQ', ph='From*')\n",
            "[1301] <label> From*\n",
            "[1307] <input> (role='combobox', value='New York NYC', ph='To*')\n",
            "[1308] <label> To*\n",
            "[1311] <button>\n",
            "[1316] <label> Dates*\n",
            "[1325] <input> (name='DepartDate', value='Jun 09', ph='Depart')\n",
            "[1333] <input> (name='ReturnDate', value='Jun 11', ph='Return')\n",
            "[1336] <button>\n",
            "[1341] <label> Travelers\n",
            "[1346] <button> 1 Adult\n",
            "[1356] <button> -\n",
            "[1358] <input> (value='1')\n",
            "[1359] <button> +\n",
            "[1366] <button> -\n",
            "[1368] <input> (value='0')\n",
            "[1369] <button> +\n",
            "[1376] <button> -\n",
            "[1378] <input> (value='0')\n",
            "[1379] <button> +\n",
            "[1386] <button> -\n",
            "[1388] <input> (value='0')\n",
            "[1389] <button> +\n",
            "[1397] <button> -\n",
            "[1399] <input> (value='0')\n",
            "[1400] <button> +\n",
            "[1407] <button> -\n",
            "[1409] <input> (value='0')\n",
            "[1410] <button> +\n",
            "[1417] <button> -\n",
            "[1419] <input> (value='0')\n",
            "[1420] <button> +\n",
            "[1427] <button> -\n",
            "[1429] <input> (value='0')\n",
            "[1430] <button> +\n",
            "[1434] <button> Travel with a pet\n",
            "[1438] <button> Clear all\n",
            "[1440] <button> Close Panel\n",
            "[1448] <button> Economy (role='combobox', name='cabinType', value='0')\n",
            "[1469] <button> Advanced search (title='Advanced search')\n",
            "[1477] <a> Bag rules (title='Bag rules')\n",
            "[1481] <a> fees for optional services (title='fees for optional services')\n",
            "[1485] <button> Find flights (type='submit')\n",
            "[1488] <button> Find your travel credits\n",
            "[1520] <button> Get 1,000 bonus miles when you book with United Packages.\n",
            "[-] <h2> Get 1,000 bonus miles when you book with United Packages.\n",
            "[1523] <button> Build your trip\n",
            "[1527] <button> (value='Play')\n",
            "[1529] <button> (value='1')\n",
            "[1530] <button> (value='2')\n",
            "[1531] <button> (value='3')\n",
            "[1532] <button> (value='4')\n",
            "[1533] <button> (value='5')\n",
            "[1534] <button> (value='6')\n",
            "[1541] <button> Advertisement by United: Advertisement: Offers up to 80,000\n",
            "[-] <h2> Pick up where you left off\n",
            "[-] <h4> Phoenix to Miami\n",
            "[1579] <button> Continue booking\n",
            "[-] <h2> Explore destinations\n",
            "[1610] <input> (role='combobox', value='Phoenix PHX', ph='Flying from')\n",
            "[195] <label> Flying from\n",
            "[1614] <label> Search type*\n",
            "[1618] <select> Roundtrip One Way (name='placeFiltersModel.searchType')\n",
            "[1619] <option> Roundtrip (value='roundTrip')\n",
            "[1621] <option> One Way (value='oneWay')\n",
            "[1630] <button> Flexible dates Use the arrow keys to navigate between days a\n",
            "[1644] <label> Max price\n",
            "[1647] <input> (value='2000')\n",
            "[1653] <button> Search (type='submit')\n",
            "[1657] <button> Refine search\n",
            "[1664] <label> Book with miles (type='checkbox')\n",
            "[1666] <input> (type='checkbox', name='awards')\n",
            "[1673] <label> Non-stop (type='checkbox')\n",
            "[1675] <input> (type='checkbox', name='nonStopOnly')\n",
            "[1682] <button> Travel interests\n",
            "[1694] <label> United airports\n",
            "[1696] <input> (type='checkbox')\n",
            "[1703] <label> Where I've been\n",
            "[1705] <input> (type='checkbox')\n",
            "[1712] <button> Reset filters\n",
            "[1726] <button> List of search results\n",
            "[-] <h3> List of search results\n",
            "[1738] <li> Los Angeles, CA, US (LAX) Fri, Apr 28 - Mon, May 1 from $148\n",
            "[1739] <button>\n",
            "[1744] <button> Los Angeles, CA, US (LAX) Fri, Apr 28 - Mon, May 1 from $148\n",
            "[1754] <li> San Francisco, CA, US (SFO) Tue, Apr 18 - Sat, Apr 22 from $\n",
            "[1755] <button>\n",
            "[1760] <button> San Francisco, CA, US (SFO) Tue, Apr 18 - Sat, Apr 22 from $\n",
            "[1770] <li> Denver, CO, US (DEN) Fri, Apr 28 - Sun, Apr 30 from $158\n",
            "[1771] <button>\n",
            "[1776] <button> Denver, CO, US (DEN) Fri, Apr 28 - Sun, Apr 30 from $158\n",
            "[1786] <li> Las Vegas, NV, US (LAS) Sat, Apr 29 - Tue, May 2 from $177\n",
            "[1787] <button>\n",
            "[1792] <button> Las Vegas, NV, US (LAS) Sat, Apr 29 - Tue, May 2 from $177\n",
            "[1802] <li> San Diego, CA, US (SAN) Sat, Apr 29 - Tue, May 2 from $177\n",
            "[1803] <button>\n",
            "[1808] <button> San Diego, CA, US (SAN) Sat, Apr 29 - Tue, May 2 from $177\n",
            "[1818] <li> Chicago, IL, US (ORD) Fri, Apr 28 - Sun, Apr 30 from $198\n",
            "[1819] <button>\n",
            "[1824] <button> Chicago, IL, US (ORD) Fri, Apr 28 - Sun, Apr 30 from $198\n",
            "[1834] <li> Dallas/Fort Worth, TX, US (DFW) Sat, Apr 29 - Tue, May 2 fro\n",
            "[1835] <button>\n",
            "[1840] <button> Dallas/Fort Worth, TX, US (DFW) Sat, Apr 29 - Tue, May 2 fro\n",
            "[1850] <li> Seattle, WA, US (SEA) Wed, Apr 19 - Mon, Apr 24 from $217\n",
            "[1851] <button>\n",
            "[1856] <button> Seattle, WA, US (SEA) Wed, Apr 19 - Mon, Apr 24 from $217\n",
            "[1866] <li> Tampa, FL, US (TPA) Fri, Apr 28 - Tue, May 2 from $217\n",
            "[1867] <button>\n",
            "[1872] <button> Tampa, FL, US (TPA) Fri, Apr 28 - Tue, May 2 from $217\n",
            "[1882] <li> Atlanta, GA, US (ATL) Sat, Apr 22 - Tue, Apr 25 from $222\n",
            "[1883] <button>\n",
            "[1888] <button> Atlanta, GA, US (ATL) Sat, Apr 22 - Tue, Apr 25 from $222\n",
            "[1898] <li> Orlando, FL, US (MCO) Sat, Apr 22 - Sat, Apr 29 from $227\n",
            "[1899] <button>\n",
            "[1904] <button> Orlando, FL, US (MCO) Sat, Apr 22 - Sat, Apr 29 from $227\n",
            "[1914] <li> New Orleans, LA, US (MSY) Fri, Apr 21 - Mon, Apr 24 from $24\n",
            "[1915] <button>\n",
            "[1920] <button> New Orleans, LA, US (MSY) Fri, Apr 21 - Mon, Apr 24 from $24\n",
            "[1930] <li> Miami, FL, US (MIA) Tue, Apr 25 - Tue, May 2 from $247\n",
            "[1931] <button>\n",
            "[1936] <button> Miami, FL, US (MIA) Tue, Apr 25 - Tue, May 2 from $247\n",
            "[1946] <li> Fort Lauderdale, FL, US (FLL) Wed, May 3 - Wed, May 10 from\n",
            "[1947] <button>\n",
            "[1952] <button> Fort Lauderdale, FL, US (FLL) Wed, May 3 - Wed, May 10 from\n",
            "[1962] <li> Toronto, ON, CA (YYZ) Sat, Apr 8 - Tue, Apr 11 from $270\n",
            "[1963] <button>\n",
            "[1968] <button> Toronto, ON, CA (YYZ) Sat, Apr 8 - Tue, Apr 11 from $270\n",
            "[1978] <li> Boston, MA, US (BOS) Mon, May 1 - Wed, May 3 from $317\n",
            "[1979] <button>\n",
            "[1984] <button> Boston, MA, US (BOS) Mon, May 1 - Wed, May 3 from $317\n",
            "[1994] <li> Cancun, MX (CUN) Sun, Apr 30 - Tue, May 2 from $486\n",
            "[1995] <button>\n",
            "[2000] <button> Cancun, MX (CUN) Sun, Apr 30 - Tue, May 2 from $486\n",
            "[2010] <li> San Jose, CA, US (SJC) Tue, May 2 - Thu, May 4 from $875\n",
            "[2011] <button>\n",
            "[2016] <button> San Jose, CA, US (SJC) Tue, May 2 - Thu, May 4 from $875\n",
            "[2028] <button> Where I've been\n",
            "[-] <h3> Where I've been\n",
            "[-] <h5> No trips yet\n",
            "[2047] <button> (title='Keyboard shortcuts')\n",
            "[3777] <button> (title='Rotate map clockwise')\n",
            "[3782] <button> (title='Rotate map counterclockwise')\n",
            "[3787] <button> (title='Tilt map')\n",
            "[3793] <button> (title='Zoom in')\n",
            "[3799] <button> (title='Zoom out')\n",
            "[3804] <button> (title='Toggle fullscreen view')\n",
            "[3810] <a> (title='Open this area in Google Maps (opens a n')\n",
            "[3822] <button> Keyboard shortcuts (title='Keyboard shortcuts')\n",
            "[3830] <button> Map Data (title='Map Data')\n",
            "[3837] <button> 500 km Click to toggle between metric and imperial units (title='Map Scale: 500 km per 53 pixels')\n",
            "[3858] <a> Terms of Use\n",
            "[3865] <a> Report a map error (title='Report errors in the road map or imagery')\n",
            "[-] <h2> Destinations for you\n",
            "[3890] <button> Book now\n",
            "[3906] <button> Book now\n",
            "[3922] <button> Book now\n",
            "[3938] <button> Book now\n",
            "[-] <h2> Trip planning made easier\n",
            "[3971] <a> Search\n",
            "\n",
            "Generate a JSON with keys: action, element_id, value, is_finished....\n",
            "\n",
            "Label:\n",
            "{\n",
            "  \"action\": \"click\",\n",
            "  \"element_id\": \"1250\",\n",
            "  \"value\": \"\",\n",
            "  \"is_finished\": false\n",
            "}\n",
            "\n",
            "--- Example 2 ---\n",
            "Prompt Snippet:\n",
            "You are a web agent. Analyze the screenshot and the list of elements.\n",
            "The element list is formatted as: [ID] <Tag> Text (Attributes).\n",
            "If the target element is not in the list, select ID 0.\n",
            "Your task is to select the correct Element ID to perform the action on.\n",
            "\n",
            "TASK: rent a car in Brooklyn - Central, NY on from April 9 to April 15.\n",
            "\n",
            "ELEMENTS:\n",
            "[0] <option> Target element is not in this list\n",
            "[-] <h1> Welcome to United.com\n",
            "[10882] <a> Skip to book\n",
            "[10897] <li> English - United States$\n",
            "[10900] <button> English - United States$\n",
            "[10908] <button>\n",
            "[10912] <li> Search\n",
            "[10913] <a> Search\n",
            "[10923] <button> Hi, James 0 miles\n",
            "[9966] <button>\n",
            "[9968] <li> Menu\n",
            "[10939] <button> Menu\n",
            "[10950] <a> BOOK (role='tab')\n",
            "[10953] <a> MY TRIPS (role='tab')\n",
            "[10956] <a> TRAVEL INFO (role='tab')\n",
            "[10959] <a> MILEAGEPLUS PROGRAM (role='tab')\n",
            "[10962] <a> DEALS (role='tab')\n",
            "[10968] <button>\n",
            "[10973] <button>\n",
            "[10978] <button>\n",
            "[10983] <button>\n",
            "[10988] <button>\n",
            "[10991] <a> Help\n",
            "[11006] <li> Book (role='tab', name='travelTab')\n",
            "[11012] <li> Flight status (role='tab', name='statusTab')\n",
            "[11018] <li> Check-in (role='tab')\n",
            "[11024] <li> My trips (role='tab')\n",
            "[11044] <li> Flight (role='tab')\n",
            "[11048] <li> Hotel (role='tab')\n",
            "[11052] <li> Car (role='tab')\n",
            "[11056] <li> Packages (role='tab')\n",
            "[11060] <li> Cruise\n",
            "[11061] <a> Cruise\n",
            "[9947] <input> (role='combobox', ph='Pickup location*')\n",
            "[11074] <label> Pickup location*\n",
            "[11078] <input> (type='checkbox', name='showDropOffLocation', value='true')\n",
            "[11079] <label> Return car to same location\n",
            "[11085] <label> Rental dates*\n",
            "[11095] <input> (name='bookCarPickupDate', ph='Pickup')\n",
            "[11103] <input> (name='bookCarDropoffDate', ph='Drop off')\n",
            "[11106] <button>\n",
            "[11111] <input> (type='checkbox', name='hideAgeBox', value='true')\n",
            "[11112] <label> Primary Driver is 25 or older\n",
            "[11119] <button> 10:00 a.m. (role='combobox', name='pickupTime', value='10|0')\n",
            "[11122] <label> Pickup time\n",
            "[11320] <button> 10:00 a.m. (role='combobox', name='dropoffTime', value='10|0')\n",
            "[11323] <label> Drop off time\n",
            "[11521] <input> (type='checkbox', name='awardCarTravel', value='on')\n",
            "[11522] <label> Book with miles\n",
            "[11529] <button> Find cars (type='submit')\n",
            "[9982] <button> Your reward is waiting at the finish line with Mile Play.\n",
            "[-] <h2> Your reward is waiting at the finish line with Mile Play.\n",
            "[9985] <button> Register now\n",
            "[9988] <button> (value='Play')\n",
            "[9990] <button> (value='1')\n",
            "[9991] <button> (value='2')\n",
            "[9992] <button> (value='3')\n",
            "[9993] <button> (value='4')\n",
            "[9994] <button> (value='5')\n",
            "[9995] <button> (value='6')\n",
            "[9997] <button> Advertisement by United: Advertisement: Offers up to 80,000\n",
            "[-] <h2> Pick up where you left off\n",
            "[-] <h4> Phoenix to Miami\n",
            "[11590] <button> Continue booking\n",
            "[-] <h2> Explore destinations\n",
            "[11616] <input> (role='combobox', value='Phoenix PHX', ph='Flying from')\n",
            "[11617] <label> Flying from\n",
            "[11621] <label> Search type*\n",
            "[11625] <select> Roundtrip One Way (name='placeFiltersModel.searchType')\n",
            "[11626] <option> Roundtrip (value='roundTrip')\n",
            "[11628] <option> One Way (value='oneWay')\n",
            "[11638] <button> Flexible dates Use the arrow keys to navigate between days a\n",
            "[11653] <label> Max price\n",
            "[11656] <input> (value='2000')\n",
            "[11662] <button> Search (type='submit')\n",
            "[11666] <button> Refine search\n",
            "[11674] <label> Book with miles (type='checkbox')\n",
            "[11676] <input> (type='checkbox', name='awards')\n",
            "[11683] <label> Non-stop (type='checkbox')\n",
            "[11685] <input> (type='checkbox', name='nonStopOnly')\n",
            "[11692] <button> Travel interests\n",
            "[11704] <label> United airports\n",
            "[11706] <input> (type='checkbox')\n",
            "[11713] <label> Where I've been\n",
            "[11715] <input> (type='checkbox')\n",
            "[11722] <button> Reset filters\n",
            "[11736] <button> List of search results\n",
            "[-] <h3> List of search results\n",
            "[11748] <li> Los Angeles, CA, US (LAX) Fri, Apr 28 - Mon, May 1 from $148\n",
            "[11749] <button>\n",
            "[11754] <button> Los Angeles, CA, US (LAX) Fri, Apr 28 - Mon, May 1 from $148\n",
            "[11764] <li> San Francisco, CA, US (SFO) Tue, Apr 18 - Sat, Apr 22 from $\n",
            "[11765] <button>\n",
            "[11770] <button> San Francisco, CA, US (SFO) Tue, Apr 18 - Sat, Apr 22 from $\n",
            "[11780] <li> Denver, CO, US (DEN) Fri, Apr 28 - Sun, Apr 30 from $158\n",
            "[11781] <button>\n",
            "[11786] <button> Denver, CO, US (DEN) Fri, Apr 28 - Sun, Apr 30 from $158\n",
            "[11796] <li> Las Vegas, NV, US (LAS) Sat, Apr 29 - Tue, May 2 from $177\n",
            "[11797] <button>\n",
            "[11802] <button> Las Vegas, NV, US (LAS) Sat, Apr 29 - Tue, May 2 from $177\n",
            "[11812] <li> San Diego, CA, US (SAN) Sat, Apr 29 - Tue, May 2 from $177\n",
            "[11813] <button>\n",
            "[11818] <button> San Diego, CA, US (SAN) Sat, Apr 29 - Tue, May 2 from $177\n",
            "[11828] <li> Chicago, IL, US (ORD) Fri, Apr 28 - Sun, Apr 30 from $198\n",
            "[11829] <button>\n",
            "[11834] <button> Chicago, IL, US (ORD) Fri, Apr 28 - Sun, Apr 30 from $198\n",
            "[11844] <li> Dallas/Fort Worth, TX, US (DFW) Sat, Apr 29 - Tue, May 2 fro\n",
            "[11845] <button>\n",
            "[11850] <button> Dallas/Fort Worth, TX, US (DFW) Sat, Apr 29 - Tue, May 2 fro\n",
            "[11860] <li> Seattle, WA, US (SEA) Wed, Apr 19 - Mon, Apr 24 from $217\n",
            "[11861] <button>\n",
            "[11866] <button> Seattle, WA, US (SEA) Wed, Apr 19 - Mon, Apr 24 from $217\n",
            "[11876] <li> Tampa, FL, US (TPA) Fri, Apr 28 - Tue, May 2 from $217\n",
            "[11877] <button>\n",
            "[11882] <button> Tampa, FL, US (TPA) Fri, Apr 28 - Tue, May 2 from $217\n",
            "[11892] <li> Atlanta, GA, US (ATL) Sat, Apr 22 - Tue, Apr 25 from $222\n",
            "[11893] <button>\n",
            "[11898] <button> Atlanta, GA, US (ATL) Sat, Apr 22 - Tue, Apr 25 from $222\n",
            "[11908] <li> Orlando, FL, US (MCO) Sat, Apr 22 - Sat, Apr 29 from $227\n",
            "[11909] <button>\n",
            "[11914] <button> Orlando, FL, US (MCO) Sat, Apr 22 - Sat, Apr 29 from $227\n",
            "[11924] <li> New Orleans, LA, US (MSY) Fri, Apr 21 - Mon, Apr 24 from $24\n",
            "[11925] <button>\n",
            "[11930] <button> New Orleans, LA, US (MSY) Fri, Apr 21 - Mon, Apr 24 from $24\n",
            "[11940] <li> Miami, FL, US (MIA) Tue, Apr 25 - Tue, May 2 from $247\n",
            "[11941] <button>\n",
            "[11946] <button> Miami, FL, US (MIA) Tue, Apr 25 - Tue, May 2 from $247\n",
            "[11956] <li> Fort Lauderdale, FL, US (FLL) Wed, May 3 - Wed, May 10 from\n",
            "[11957] <button>\n",
            "[11962] <button> Fort Lauderdale, FL, US (FLL) Wed, May 3 - Wed, May 10 from\n",
            "[11972] <li> Toronto, ON, CA (YYZ) Sat, Apr 8 - Tue, Apr 11 from $270\n",
            "[11973] <button>\n",
            "[11978] <button> Toronto, ON, CA (YYZ) Sat, Apr 8 - Tue, Apr 11 from $270\n",
            "[11988] <li> Boston, MA, US (BOS) Mon, May 1 - Wed, May 3 from $317\n",
            "[11989] <button>\n",
            "[11994] <button> Boston, MA, US (BOS) Mon, May 1 - Wed, May 3 from $317\n",
            "[12004] <li> Cancun, MX (CUN) Sun, Apr 30 - Tue, May 2 from $486\n",
            "[12005] <button>\n",
            "[12010] <button> Cancun, MX (CUN) Sun, Apr 30 - Tue, May 2 from $486\n",
            "[12020] <li> San Jose, CA, US (SJC) Tue, May 2 - Thu, May 4 from $875\n",
            "[12021] <button>\n",
            "[12026] <button> San Jose, CA, US (SJC) Tue, May 2 - Thu, May 4 from $875\n",
            "[12038] <button> Where I've been\n",
            "[-] <h3> Where I've been\n",
            "[-] <h5> No trips yet\n",
            "[12057] <button> (title='Keyboard shortcuts')\n",
            "[13787] <button> (title='Rotate map clockwise')\n",
            "[13792] <button> (title='Rotate map counterclockwise')\n",
            "[13797] <button> (title='Tilt map')\n",
            "[13803] <button> (title='Zoom in')\n",
            "[13809] <button> (title='Zoom out')\n",
            "[13814] <button> (title='Toggle fullscreen view')\n",
            "[13820] <a> (title='Open this area in Google Maps (opens a n')\n",
            "[13832] <button> Keyboard shortcuts (title='Keyboard shortcuts')\n",
            "[13840] <button> Map Data (title='Map Data')\n",
            "[13847] <button> 500 km Click to toggle between metric and imperial units (title='Map Scale: 500 km per 53 pixels')\n",
            "[13868] <a> Terms of Use\n",
            "[13875] <a> Report a map error (title='Report errors in the road map or imagery')\n",
            "[-] <h2> Destinations for you\n",
            "[13900] <button> Book now\n",
            "[13916] <button> Book now\n",
            "[13932] <button> Book now\n",
            "[13948] <button> Book now\n",
            "[-] <h2> Trip planning made easier\n",
            "[13981] <a> Search\n",
            "[13998] <a> Search\n",
            "[14015] <a> Learn more\n",
            "[-] <h2> What to expect when you fly\n",
            "[-] <h3> Keeping you safe\n",
            "[14044] <a> Learn how\n",
            "[-] <h3> Changing the way you travel\n",
            "[14058] <a> Touchless check-in Check your bags while practicing social d\n",
            "[14070] <a> Our award-winning app Manage your trip while reducing touchp\n",
            "[14097] <button> Advertisement by United: Get more with Avis and Budget. Save\n",
            "[14104] <button> Advertisement by United: Plan your next adventure. Reveal yo\n",
            "[14111] <button> Advertisement by United: Soar above the rest. Earn 2x miles\n",
            "[-] <h1> Search\n",
            "[14637] <button> Close dialog\n",
            "[-] <h2> Add to favorites\n",
            "[14679] <button> Close dialog\n",
            "[-] <h2> Add to favorites\n",
            "[14715] <button> Close dialog\n",
            "[10010] <button> Site Feedback (role='button')\n",
            "\n",
            "Generate a JSON with keys: action, element_id, value, is_finished....\n",
            "\n",
            "Label:\n",
            "{\n",
            "  \"action\": \"type\",\n",
            "  \"element_id\": \"9947\",\n",
            "  \"value\": \"Brooklyn Central\",\n",
            "  \"is_finished\": false\n",
            "}\n",
            "\n",
            "--- Example 3 ---\n",
            "Prompt Snippet:\n",
            "You are a web agent. Analyze the screenshot and the list of elements.\n",
            "The element list is formatted as: [ID] <Tag> Text (Attributes).\n",
            "If the target element is not in the list, select ID 0.\n",
            "Your task is to select the correct Element ID to perform the action on.\n",
            "\n",
            "TASK: rent a car in Brooklyn - Central, NY on from April 9 to April 15.\n",
            "\n",
            "ELEMENTS:\n",
            "[0] <option> Target element is not in this list\n",
            "[-] <h1> Welcome to United.com\n",
            "[20902] <a> Skip to book\n",
            "[20917] <li> English - United States$\n",
            "[20920] <button> English - United States$\n",
            "[20928] <button>\n",
            "[20932] <li> Search\n",
            "[20933] <a> Search\n",
            "[20943] <button> Hi, James 0 miles\n",
            "[19977] <button>\n",
            "[19979] <li> Menu\n",
            "[20959] <button> Menu\n",
            "[20970] <a> BOOK (role='tab')\n",
            "[20973] <a> MY TRIPS (role='tab')\n",
            "[20976] <a> TRAVEL INFO (role='tab')\n",
            "[20979] <a> MILEAGEPLUS PROGRAM (role='tab')\n",
            "[20982] <a> DEALS (role='tab')\n",
            "[20988] <button>\n",
            "[20993] <button>\n",
            "[20998] <button>\n",
            "[21003] <button>\n",
            "[21008] <button>\n",
            "[21011] <a> Help\n",
            "[21026] <li> Book (role='tab', name='travelTab')\n",
            "[21032] <li> Flight status (role='tab', name='statusTab')\n",
            "[21038] <li> Check-in (role='tab')\n",
            "[21044] <li> My trips (role='tab')\n",
            "[21064] <li> Flight (role='tab')\n",
            "[21068] <li> Hotel (role='tab')\n",
            "[21072] <li> Car (role='tab')\n",
            "[21076] <li> Packages (role='tab')\n",
            "[21080] <li> Cruise\n",
            "[21081] <a> Cruise\n",
            "[21094] <input> (role='combobox', value='Brooklyn Central', ph='Pickup location*')\n",
            "[21095] <label> Pickup location*\n",
            "[21098] <ul> Brooklyn - Central (New York), US 309A, 178A, Purv Marg, Ind (role='listbox')\n",
            "[21099] <li> Brooklyn - Central (New York), US (role='option')\n",
            "[19984] <button> Brooklyn - Central (New York), US\n",
            "[19986] <li> 309A, 178A, Purv Marg, Industrial Area Phase I, Chandigarh, (role='option')\n",
            "[19987] <button> 309A, 178A, Purv Marg, Industrial Area Phase I, Chandigarh,\n",
            "[19989] <li> Coal Depot Complex, 10D, Sector 10, Chandigarh, 160011, Indi (role='option')\n",
            "[19990] <button> Coal Depot Complex, 10D, Sector 10, Chandigarh, 160011, Indi\n",
            "[21111] <input> (type='checkbox', name='showDropOffLocation', value='true')\n",
            "[21112] <label> Return car to same location\n",
            "[21118] <label> Rental dates*\n",
            "[21128] <input> (name='bookCarPickupDate', ph='Pickup')\n",
            "[21136] <input> (name='bookCarDropoffDate', ph='Drop off')\n",
            "[21139] <button>\n",
            "[21144] <input> (type='checkbox', name='hideAgeBox', value='true')\n",
            "[21145] <label> Primary Driver is 25 or older\n",
            "[21152] <button> 10:00 a.m. (role='combobox', name='pickupTime', value='10|0')\n",
            "[21155] <label> Pickup time\n",
            "[21353] <button> 10:00 a.m. (role='combobox', name='dropoffTime', value='10|0')\n",
            "[21356] <label> Drop off time\n",
            "[21554] <input> (type='checkbox', name='awardCarTravel', value='on')\n",
            "[21555] <label> Book with miles\n",
            "[21562] <button> Find cars (type='submit')\n",
            "[20002] <button> Offers up to 80,000 bonus miles.\n",
            "[-] <h2> Offers up to 80,000 bonus miles.\n",
            "[20005] <button> Learn more\n",
            "[20008] <button> (value='Play')\n",
            "[20010] <button> (value='1')\n",
            "[20011] <button> (value='2')\n",
            "[20012] <button> (value='3')\n",
            "[20013] <button> (value='4')\n",
            "[20014] <button> (value='5')\n",
            "[20015] <button> (value='6')\n",
            "[20017] <button> Advertisement by United: Advertisement: Offers up to 80,000\n",
            "[-] <h2> Pick up where you left off\n",
            "[-] <h4> Phoenix to Miami\n",
            "[21623] <button> Continue booking\n",
            "[-] <h2> Explore destinations\n",
            "[21649] <input> (role='combobox', value='Phoenix PHX', ph='Flying from')\n",
            "[21650] <label> Flying from\n",
            "[21654] <label> Search type*\n",
            "[21658] <select> Roundtrip One Way (name='placeFiltersModel.searchType')\n",
            "[21659] <option> Roundtrip (value='roundTrip')\n",
            "[21661] <option> One Way (value='oneWay')\n",
            "[21671] <button> Flexible dates Use the arrow keys to navigate between days a\n",
            "[21686] <label> Max price\n",
            "[21689] <input> (value='2000')\n",
            "[21695] <button> Search (type='submit')\n",
            "[21699] <button> Refine search\n",
            "[21707] <label> Book with miles (type='checkbox')\n",
            "[21709] <input> (type='checkbox', name='awards')\n",
            "[21716] <label> Non-stop (type='checkbox')\n",
            "[21718] <input> (type='checkbox', name='nonStopOnly')\n",
            "[21725] <button> Travel interests\n",
            "[21737] <label> United airports\n",
            "[21739] <input> (type='checkbox')\n",
            "[21746] <label> Where I've been\n",
            "[21748] <input> (type='checkbox')\n",
            "[21755] <button> Reset filters\n",
            "[21769] <button> List of search results\n",
            "[-] <h3> List of search results\n",
            "[21781] <li> Los Angeles, CA, US (LAX) Fri, Apr 28 - Mon, May 1 from $148\n",
            "[21782] <button>\n",
            "[21787] <button> Los Angeles, CA, US (LAX) Fri, Apr 28 - Mon, May 1 from $148\n",
            "[21797] <li> San Francisco, CA, US (SFO) Tue, Apr 18 - Sat, Apr 22 from $\n",
            "[21798] <button>\n",
            "[21803] <button> San Francisco, CA, US (SFO) Tue, Apr 18 - Sat, Apr 22 from $\n",
            "[21813] <li> Denver, CO, US (DEN) Fri, Apr 28 - Sun, Apr 30 from $158\n",
            "[21814] <button>\n",
            "[21819] <button> Denver, CO, US (DEN) Fri, Apr 28 - Sun, Apr 30 from $158\n",
            "[21829] <li> Las Vegas, NV, US (LAS) Sat, Apr 29 - Tue, May 2 from $177\n",
            "[21830] <button>\n",
            "[21835] <button> Las Vegas, NV, US (LAS) Sat, Apr 29 - Tue, May 2 from $177\n",
            "[21845] <li> San Diego, CA, US (SAN) Sat, Apr 29 - Tue, May 2 from $177\n",
            "[21846] <button>\n",
            "[21851] <button> San Diego, CA, US (SAN) Sat, Apr 29 - Tue, May 2 from $177\n",
            "[21861] <li> Chicago, IL, US (ORD) Fri, Apr 28 - Sun, Apr 30 from $198\n",
            "[21862] <button>\n",
            "[21867] <button> Chicago, IL, US (ORD) Fri, Apr 28 - Sun, Apr 30 from $198\n",
            "[21877] <li> Dallas/Fort Worth, TX, US (DFW) Sat, Apr 29 - Tue, May 2 fro\n",
            "[21878] <button>\n",
            "[21883] <button> Dallas/Fort Worth, TX, US (DFW) Sat, Apr 29 - Tue, May 2 fro\n",
            "[21893] <li> Seattle, WA, US (SEA) Wed, Apr 19 - Mon, Apr 24 from $217\n",
            "[21894] <button>\n",
            "[21899] <button> Seattle, WA, US (SEA) Wed, Apr 19 - Mon, Apr 24 from $217\n",
            "[21909] <li> Tampa, FL, US (TPA) Fri, Apr 28 - Tue, May 2 from $217\n",
            "[21910] <button>\n",
            "[21915] <button> Tampa, FL, US (TPA) Fri, Apr 28 - Tue, May 2 from $217\n",
            "[21925] <li> Atlanta, GA, US (ATL) Sat, Apr 22 - Tue, Apr 25 from $222\n",
            "[21926] <button>\n",
            "[21931] <button> Atlanta, GA, US (ATL) Sat, Apr 22 - Tue, Apr 25 from $222\n",
            "[21941] <li> Orlando, FL, US (MCO) Sat, Apr 22 - Sat, Apr 29 from $227\n",
            "[21942] <button>\n",
            "[21947] <button> Orlando, FL, US (MCO) Sat, Apr 22 - Sat, Apr 29 from $227\n",
            "[21957] <li> New Orleans, LA, US (MSY) Fri, Apr 21 - Mon, Apr 24 from $24\n",
            "[21958] <button>\n",
            "[21963] <button> New Orleans, LA, US (MSY) Fri, Apr 21 - Mon, Apr 24 from $24\n",
            "[21973] <li> Miami, FL, US (MIA) Tue, Apr 25 - Tue, May 2 from $247\n",
            "[21974] <button>\n",
            "[21979] <button> Miami, FL, US (MIA) Tue, Apr 25 - Tue, May 2 from $247\n",
            "[21989] <li> Fort Lauderdale, FL, US (FLL) Wed, May 3 - Wed, May 10 from\n",
            "[21990] <button>\n",
            "[21995] <button> Fort Lauderdale, FL, US (FLL) Wed, May 3 - Wed, May 10 from\n",
            "[22005] <li> Toronto, ON, CA (YYZ) Sat, Apr 8 - Tue, Apr 11 from $270\n",
            "[22006] <button>\n",
            "[22011] <button> Toronto, ON, CA (YYZ) Sat, Apr 8 - Tue, Apr 11 from $270\n",
            "[22021] <li> Boston, MA, US (BOS) Mon, May 1 - Wed, May 3 from $317\n",
            "[22022] <button>\n",
            "[22027] <button> Boston, MA, US (BOS) Mon, May 1 - Wed, May 3 from $317\n",
            "[22037] <li> Cancun, MX (CUN) Sun, Apr 30 - Tue, May 2 from $486\n",
            "[22038] <button>\n",
            "[22043] <button> Cancun, MX (CUN) Sun, Apr 30 - Tue, May 2 from $486\n",
            "[22053] <li> San Jose, CA, US (SJC) Tue, May 2 - Thu, May 4 from $875\n",
            "[22054] <button>\n",
            "[22059] <button> San Jose, CA, US (SJC) Tue, May 2 - Thu, May 4 from $875\n",
            "[22071] <button> Where I've been\n",
            "[-] <h3> Where I've been\n",
            "[-] <h5> No trips yet\n",
            "[22090] <button> (title='Keyboard shortcuts')\n",
            "[23820] <button> (title='Rotate map clockwise')\n",
            "[23825] <button> (title='Rotate map counterclockwise')\n",
            "[23830] <button> (title='Tilt map')\n",
            "[23836] <button> (title='Zoom in')\n",
            "[23842] <button> (title='Zoom out')\n",
            "[23847] <button> (title='Toggle fullscreen view')\n",
            "[23853] <a> (title='Open this area in Google Maps (opens a n')\n",
            "[23865] <button> Keyboard shortcuts (title='Keyboard shortcuts')\n",
            "[23873] <button> Map Data (title='Map Data')\n",
            "[23880] <button> 500 km Click to toggle between metric and imperial units (title='Map Scale: 500 km per 53 pixels')\n",
            "[23901] <a> Terms of Use\n",
            "[23908] <a> Report a map error (title='Report errors in the road map or imagery')\n",
            "[-] <h2> Destinations for you\n",
            "[23933] <button> Book now\n",
            "[23949] <button> Book now\n",
            "[23965] <button> Book now\n",
            "[23981] <button> Book now\n",
            "[-] <h2> Trip planning made easier\n",
            "[24014] <a> Search\n",
            "[24031] <a> Search\n",
            "[24048] <a> Learn more\n",
            "[-] <h2> What to expect when you fly\n",
            "[-] <h3> Keeping you safe\n",
            "[24077] <a> Learn how\n",
            "[-] <h3> Changing the way you travel\n",
            "[24091] <a> Touchless check-in Check your bags while practicing social d\n",
            "[24103] <a> Our award-winning app Manage your trip while reducing touchp\n",
            "[24130] <button> Advertisement by United: Get more with Avis and Budget. Save\n",
            "[24137] <button> Advertisement by United: Plan your next adventure. Reveal yo\n",
            "[24144] <button> Advertisement by United: Soar above the rest. Earn 2x miles\n",
            "[-] <h1> Search\n",
            "[24670] <button> Close dialog\n",
            "[-] <h2> Add to favorites\n",
            "[24712] <button> Close dialog\n",
            "[-] <h2> Add to favorites\n",
            "[24748] <button> Close dialog\n",
            "[20030] <button> Site Feedback (role='button')\n",
            "\n",
            "Generate a JSON with keys: action, element_id, value, is_finished....\n",
            "\n",
            "Label:\n",
            "{\n",
            "  \"action\": \"click\",\n",
            "  \"element_id\": \"19984\",\n",
            "  \"value\": \"\",\n",
            "  \"is_finished\": false\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "# --- Access the file from your mounted Google Drive ---\n",
        "\n",
        "# The path to your file is now fixed and reliable.\n",
        "# 'My Drive' is the standard name for the root of your Google Drive.\n",
        "FILENAME = \"/workspace/mind2web_processed_train.jsonl\"\n",
        "\n",
        "NUM_LINES_TO_CHECK = 3\n",
        "\n",
        "print(f\"--- Checking the first {NUM_LINES_TO_CHECK} lines of the file from Google Drive ---\")\n",
        "\n",
        "with open(FILENAME, \"r\") as f:\n",
        "    for i, line in enumerate(f):\n",
        "        if i >= NUM_LINES_TO_CHECK:\n",
        "            break\n",
        "\n",
        "        # Parse the JSON string from the line into a Python dictionary\n",
        "        data = json.loads(line)\n",
        "\n",
        "        print(f\"\\n--- Example {i+1} ---\")\n",
        "        print(\"Prompt Snippet:\")\n",
        "        # Print the first 200 characters of the prompt\n",
        "        print(data['prompt'] + \"...\")\n",
        "\n",
        "        print(\"\\nLabel:\")\n",
        "        # The label is a string, so we can parse it again to pretty-print\n",
        "        pretty_label = json.loads(data['label'])\n",
        "        print(json.dumps(pretty_label, indent=2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SvNRn8Isu8rY"
      },
      "source": [
        "## Screenshot saving"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OzfbXvoQLoT3"
      },
      "outputs": [],
      "source": [
        "#saving cropped screenshots\n",
        "\n",
        "from PIL import Image\n",
        "import os\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "# IMPORTANT: Allow loading large images to prevent \"DecompressionBombError\"\n",
        "Image.MAX_IMAGE_PIXELS = None\n",
        "\n",
        "SAVE_DIR = \"/content/drive/My Drive/m2w_i\"\n",
        "os.makedirs(SAVE_DIR, exist_ok=True)\n",
        "\n",
        "# 1. FIXED WIDTH: 1024 is standard for 7B VLMs.\n",
        "# It keeps text readable but is much cheaper than 1280.\n",
        "TARGET_WIDTH = 1024\n",
        "\n",
        "# 2. MAX HEIGHT: We hard-crop anything below this.\n",
        "# 1280 height usually covers the \"fold\" and slightly more.\n",
        "MAX_HEIGHT = 1280\n",
        "\n",
        "print(f\"Saving screenshots to: {SAVE_DIR}\")\n",
        "print(f\"Strategy: Resize width to {TARGET_WIDTH}px, then CROP height to max {MAX_HEIGHT}px.\")\n",
        "\n",
        "for example in tqdm(multimodal_dataset):\n",
        "    try:\n",
        "        annotation_id = example[\"annotation_id\"]\n",
        "        img = example[\"screenshot\"]  # PIL image\n",
        "\n",
        "        # --- NEW RESIZING LOGIC ---\n",
        "\n",
        "        # 1. Calculate new height to preserve aspect ratio\n",
        "        w_percent = (TARGET_WIDTH / float(img.size[0]))\n",
        "        h_size = int((float(img.size[1]) * float(w_percent)))\n",
        "\n",
        "        # 2. Resize the image (High Quality)\n",
        "        # We enforce the width, letting height float\n",
        "        img_resized = img.resize((TARGET_WIDTH, h_size), Image.LANCZOS)\n",
        "\n",
        "        # 3. Smart Crop (Viewport Simulation)\n",
        "        # If the resulting image is too tall, we chop off the bottom.\n",
        "        # This keeps the header/nav/main content crisp.\n",
        "        if h_size > MAX_HEIGHT:\n",
        "            # Crop box: (left, upper, right, lower)\n",
        "            img_resized = img_resized.crop((0, 0, TARGET_WIDTH, MAX_HEIGHT))\n",
        "\n",
        "        # --- END OF NEW CODE ---\n",
        "\n",
        "        # Save as JPEG (optimized)\n",
        "        path = os.path.join(SAVE_DIR, f\"{annotation_id}.jpeg\")\n",
        "        img_resized.convert('RGB').save(path, quality=85)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Skipping {annotation_id} because of error: {e}\")\n",
        "\n",
        "print(\"Done saving all processed images.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kbzjF_PLu361"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "print(\"Zipping images on Drive... this takes a minute...\")\n",
        "shutil.make_archive(\"/content/drive/My Drive/m2w_images\", 'zip', \"/content/drive/My Drive/m2w_i\")\n",
        "print(\"Done! Created m2w_images.zip on your Drive.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xm6yW0QWv7oY"
      },
      "source": [
        "### Download Screenshots to local"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ur67AkQEu4oO"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Path to local fast disk\n",
        "LOCAL_IMAGE_FOLDER = \"/content/m2w_i_local\"\n",
        "ZIP_PATH = \"/content/drive/My Drive/m2w_images.zip\"\n",
        "\n",
        "if not os.path.exists(LOCAL_IMAGE_FOLDER):\n",
        "    print(\" Copying ZIP from Drive...\")\n",
        "    !cp \"{ZIP_PATH}\" /content/temp_images.zip\n",
        "\n",
        "    print(\" Unzipping to local disk...\")\n",
        "    !unzip -q /content/temp_images.zip -d \"{LOCAL_IMAGE_FOLDER}\"\n",
        "\n",
        "    print(f\" Ready! Images are at {LOCAL_IMAGE_FOLDER}\")\n",
        "else:\n",
        "    print(\" Images already loaded.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8OQ2G4maU3aZ"
      },
      "source": [
        "#  Part 3: FineTune Qwen2.5-VL 7B via LoRA (NEW) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DLZbuYNvXaaO"
      },
      "source": [
        "## Dataset Builder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KNtoNgd2bvcs",
        "outputId": "d74a7cee-b7b1-475c-cba4-d095432a1b95"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: 'Could not load this library: /usr/local/lib/python3.10/dist-packages/torchvision/image.so'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
            "  warn(\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoModelForCausalLM, AutoProcessor\n",
        "import torch\n",
        "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0LEw3KEx13Gf"
      },
      "outputs": [],
      "source": [
        "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "torch.cuda.reset_peak_memory_stats()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "c7d434f9db0a4801ab601b9b4b6cb288",
            "6a9d7bdd561f48bda617bafcc3aba715",
            "d841bdcbc4b445d0a2c337ff6de0eb84",
            "52ada261d08840edb5c0065c9bcfad01",
            "e57e0e786fee4ec78a9366f0526ad3b0",
            "a208458b42de411a80390a6695063dc0",
            "abf09082f22e4d30a95e750977d98c74",
            "08b642cc13e348438c1a32ae70dc2b6a",
            "b860bfcbaa314c2d99a4068043d907f3",
            "c3a1d4104aa94fe3b91f57562ecbf392",
            "20c98509cae045748a25e6c80100bcd8",
            "f3dea134c3d14e62b3a8eb3edec0566d"
          ]
        },
        "id": "ySjDp5A7bv_6",
        "outputId": "a879acf0-1402-451b-a7e2-1fe0bf5178ee"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f3dea134c3d14e62b3a8eb3edec0566d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from transformers import AutoProcessor, AutoModelForImageTextToText, BitsAndBytesConfig, Qwen2_5_VLForConditionalGeneration\n",
        "\n",
        "model_id = \"Qwen/Qwen2.5-VL-7B-Instruct\"\n",
        "\n",
        "processor = AutoProcessor.from_pretrained(\n",
        "    model_id,\n",
        "    trust_remote_code=True,\n",
        "    use_fast=False,\n",
        ")\n",
        "\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16\n",
        ")\n",
        "\n",
        "model = Qwen2_5_VLForConditionalGeneration.from_pretrained(\n",
        "    \"Qwen/Qwen2.5-VL-7B-Instruct\",\n",
        "    device_map=\"auto\",\n",
        "    quantization_config=bnb_config\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IwpKpDsIb2Ls",
        "outputId": "47d1ba32-5354-41bb-8bfb-359c5afdf63d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " FORCED GRADIENTS: base_model.model.model.language_model.embed_tokens\n",
            "trainable params: 568,792,064 || all params: 8,315,961,344 || trainable%: 6.8398\n"
          ]
        }
      ],
      "source": [
        "prepare_model_for_kbit_training(model)\n",
        "\n",
        "lora = LoraConfig(\n",
        "    r=8,\n",
        "    lora_alpha=16,\n",
        "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
        "    lora_dropout=0.05,\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\"\n",
        ")\n",
        "model = get_peft_model(model, lora)\n",
        "\n",
        "# The standard model.enable_input_require_grads() is failing silently.\n",
        "# We do it manually here.\n",
        "def make_inputs_require_grad(module):\n",
        "    found = False\n",
        "    for name, child in module.named_modules():\n",
        "        if isinstance(child, torch.nn.Embedding):\n",
        "            # Force gradients on the embedding layer\n",
        "            child.weight.requires_grad_(True)\n",
        "            print(f\" FORCED GRADIENTS: {name}\")\n",
        "            found = True\n",
        "    if not found:\n",
        "        print(\" WARNING: Could not find embedding layer to unlock!\")\n",
        "\n",
        "make_inputs_require_grad(model)\n",
        "model.gradient_checkpointing_enable()\n",
        "model.print_trainable_parameters()\n",
        "model.config.use_cache = False\n",
        "\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R1OU3QrDW8BD"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "from PIL import Image, UnidentifiedImageError\n",
        "import os, json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "efT0Wof5i7YR"
      },
      "outputs": [],
      "source": [
        "def safe_open(path):\n",
        "    try:\n",
        "        return Image.open(path).convert(\"RGB\")\n",
        "    except Exception:\n",
        "        return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "by4sTkTZW9_Y"
      },
      "outputs": [],
      "source": [
        "class Mind2WebQwenVLDataset(Dataset):\n",
        "    def __init__(self, jsonl_path, image_folder, processor, skip_checks=False):\n",
        "        self.processor = processor\n",
        "        self.image_folder = image_folder\n",
        "        self.skip_checks = skip_checks\n",
        "\n",
        "        # Track removed samples (only used if skip_checks=False)\n",
        "        self.removed_ids = []\n",
        "\n",
        "        # Load all JSON samples\n",
        "        with open(jsonl_path, \"r\") as f:\n",
        "            raw = [json.loads(line) for line in f]\n",
        "\n",
        "        self.samples = []\n",
        "        removed = 0\n",
        "\n",
        "        for s in raw:\n",
        "            annotation_id = s[\"annotation_id\"]\n",
        "\n",
        "            # If skip_checks is True, just store the sample and continue\n",
        "            if self.skip_checks:\n",
        "                s[\"_image_path\"] = os.path.join(image_folder, f\"{annotation_id}.jpeg\")\n",
        "                self.samples.append(s)\n",
        "                continue\n",
        "\n",
        "            # Otherwise, check image existence/corruption\n",
        "            img_path = None\n",
        "            for ext in [\"png\", \"jpg\", \"jpeg\", \"webp\"]:\n",
        "                p = os.path.join(image_folder, f\"{annotation_id}.{ext}\")\n",
        "                if os.path.isfile(p):\n",
        "                    img_path = p\n",
        "                    break\n",
        "\n",
        "            if img_path is None:\n",
        "                removed += 1\n",
        "                self.removed_ids.append(annotation_id)\n",
        "                continue\n",
        "\n",
        "            img = safe_open(img_path)\n",
        "            if img is None:\n",
        "                removed += 1\n",
        "                self.removed_ids.append(annotation_id)\n",
        "                continue\n",
        "\n",
        "            s[\"_image_path\"] = img_path\n",
        "            self.samples.append(s)\n",
        "            print(f\"Sample Image Path: {self.samples[0]['_image_path']}\")\n",
        "\n",
        "        if not self.skip_checks:\n",
        "            print(f\"Filtered dataset: {len(raw)}  {len(self.samples)} ({removed} removed)\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sample = self.samples[idx]\n",
        "\n",
        "        # If skip_checks=True, reconstruct the image path assuming cleaned dataset\n",
        "        if self.skip_checks:\n",
        "            # adjust extension if needed\n",
        "            img_path = os.path.join(self.image_folder, f\"{sample['annotation_id']}.jpeg\")\n",
        "        else:\n",
        "            img_path = sample[\"_image_path\"]\n",
        "\n",
        "        try:\n",
        "            with Image.open(img_path) as f:\n",
        "                img = f.convert(\"RGB\")\n",
        "        except Exception:\n",
        "            # Fallback for stability\n",
        "            img = Image.new(\"RGB\", (1024, 1024), (0, 0, 0))\n",
        "\n",
        "        messages = [\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": [\n",
        "                    {\"type\": \"text\", \"text\": sample[\"prompt\"]},\n",
        "                    {\"type\": \"image\", \"image\": img},\n",
        "                ],\n",
        "            },\n",
        "            {\n",
        "                \"role\": \"assistant\",\n",
        "                \"content\": [\n",
        "                    {\"type\": \"text\", \"text\": sample[\"label\"]},\n",
        "                ],\n",
        "            },\n",
        "        ]\n",
        "\n",
        "        return messages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tPWk1gvqXQSP"
      },
      "outputs": [],
      "source": [
        "def qwen_collate_fn(batch):\n",
        "    texts = []\n",
        "    images = []\n",
        "\n",
        "    for messages in batch:\n",
        "        # Extract the formatted prompt via the chat template\n",
        "        txt = processor.apply_chat_template(\n",
        "            messages,\n",
        "            tokenize=False,\n",
        "            add_generation_prompt=False\n",
        "        )\n",
        "        texts.append(txt)\n",
        "\n",
        "        # Extract images (one per example here)\n",
        "        img = [c[\"image\"] for c in messages[0][\"content\"] if c[\"type\"] == \"image\"]\n",
        "        images.append(img)\n",
        "\n",
        "    # Processor handles image + text merging into the multimodal embedding\n",
        "    out = processor(\n",
        "        text=texts,\n",
        "        images=images,\n",
        "        padding=True,\n",
        "        return_tensors=\"pt\",\n",
        "        max_length=8192,\n",
        "        truncation=True\n",
        "    )\n",
        "\n",
        "    out[\"labels\"] = out[\"input_ids\"].clone()\n",
        "    return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wiRNw6aAyo8g"
      },
      "source": [
        "## For filtering out the corrupted samples and saving to new dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BU9wrpsGXWAZ"
      },
      "outputs": [],
      "source": [
        "dataset = Mind2WebQwenVLDataset(\n",
        "    jsonl_path=\"/content/drive/My Drive/mind2web_processed_train.jsonl\",\n",
        "    image_folder=\"/content/m2w_i_local\",\n",
        "    processor=processor\n",
        ")\n",
        "\n",
        "loader = DataLoader(\n",
        "    dataset,\n",
        "    batch_size=1,\n",
        "    shuffle=True,\n",
        "    collate_fn=qwen_collate_fn\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tBV5ztETs5dZ"
      },
      "outputs": [],
      "source": [
        "print(dataset.removed_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bk0L2dB0s5-Y"
      },
      "outputs": [],
      "source": [
        "for ann_id in dataset.removed_ids:\n",
        "    for ext in [\"png\", \"jpg\", \"jpeg\", \"webp\"]:\n",
        "        path = os.path.join(\"/content/drive/My Drive/m2w_i\", f\"{ann_id}.{ext}\")\n",
        "        if os.path.isfile(path):\n",
        "            os.remove(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tv6FYfoEs7XY"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "removed = set(dataset.removed_ids)\n",
        "cleaned = []\n",
        "\n",
        "with open(\"/content/drive/My Drive/mind2web_processed_train.jsonl\") as f:\n",
        "    for line in f:\n",
        "        js = json.loads(line)\n",
        "        if js[\"annotation_id\"] not in removed:\n",
        "            cleaned.append(js)\n",
        "\n",
        "with open(\"/content/drive/My Drive/mind2web_processed_train_clean.jsonl\", \"w\") as f:\n",
        "    for js in cleaned:\n",
        "        f.write(json.dumps(js) + \"\\n\")\n",
        "\n",
        "print(\"Wrote cleaned JSONL:\", len(cleaned))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0uE3ShDDzBPh"
      },
      "source": [
        "##   for loading in the saved dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZHOOP7h8wsWV",
        "outputId": "2e70e02a-81ff-4a3d-8602-f731e213d1a4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of examples: 5743\n"
          ]
        }
      ],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "dataset = Mind2WebQwenVLDataset(\n",
        "    jsonl_path=\"/workspace/mind2web_processed_train.jsonl\",\n",
        "    image_folder=\"/workspace/m2w_i_local\",\n",
        "    processor=processor,\n",
        "    skip_checks=True\n",
        ")\n",
        "\n",
        "loader = DataLoader(\n",
        "    dataset,\n",
        "    batch_size=1,\n",
        "    shuffle=True,\n",
        "    collate_fn=qwen_collate_fn,\n",
        "    num_workers=2,\n",
        "    pin_memory=True,\n",
        "    persistent_workers=True\n",
        ")\n",
        "\n",
        "print(f\"Number of examples: {len(dataset)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "veR_Gbw9dr5c"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from tqdm import tqdm\n",
        "\n",
        "#optional: cautionary check for max input sequence token length + max image token length\n",
        "\n",
        "max_seq_len = 0\n",
        "max_pixel_dim0 = 0\n",
        "max_pixel_shape = None\n",
        "\n",
        "# We'll also store the ID of the problematic samples for inspection\n",
        "sample_with_max_seq = None\n",
        "sample_with_max_pixel = None\n",
        "\n",
        "# Loop through the dataset with a progress bar\n",
        "for i in tqdm(range(len(dataset)), desc=\"Analyzing dataset samples\"):\n",
        "    # Get the raw messages for one sample\n",
        "    messages = dataset[i]\n",
        "\n",
        "    # Use the collate function to process it, wrapping it in a list to simulate a batch of 1\n",
        "    batch = qwen_collate_fn([messages])\n",
        "\n",
        "    # --- Check sequence length ---\n",
        "    current_seq_len = batch['input_ids'].shape[1]\n",
        "    if current_seq_len > max_seq_len:\n",
        "        max_seq_len = current_seq_len\n",
        "        # Get the original sample's metadata to find the ID\n",
        "        sample_with_max_seq = dataset.samples[i]['annotation_id']\n",
        "\n",
        "    # --- Check pixel_values dimensions ---\n",
        "    current_pixel_shape = batch['pixel_values'].shape\n",
        "    # The first dimension is usually the one that varies with image size/patches\n",
        "    current_pixel_dim0 = current_pixel_shape[0]\n",
        "\n",
        "    if current_pixel_dim0 > max_pixel_dim0:\n",
        "        max_pixel_dim0 = current_pixel_dim0\n",
        "        max_pixel_shape = current_pixel_shape\n",
        "        sample_with_max_pixel = dataset.samples[i]['annotation_id']\n",
        "\n",
        "# --- Print the results ---\n",
        "print(\"\\n--- Analysis Complete ---\")\n",
        "print(f\"Max sequence length found: {max_seq_len}\")\n",
        "print(f\"  - Found in sample ID: {sample_with_max_seq}\\n\")\n",
        "\n",
        "print(f\"Max pixel_values shape found: {max_pixel_shape}\")\n",
        "print(f\"  - Found in sample ID: {sample_with_max_pixel}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zv7aAhg_wt7J",
        "outputId": "5e3148e0-6fd9-436b-f766-bdcfa30856e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "KeysView({'input_ids': tensor([[151644,   8948,    198,  ...,     92, 151645,    198]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]]), 'pixel_values': tensor([[-0.7704, -0.7704, -0.7704,  ..., -0.2573, -0.2573, -0.2573],\n",
            "        [-0.7704, -0.7704, -0.7704,  ..., -0.2573, -0.2573, -0.2573],\n",
            "        [-0.7704, -0.7704, -0.7704,  ..., -0.2289, -0.2289, -0.2289],\n",
            "        ...,\n",
            "        [ 1.9303,  1.9303,  1.9303,  ...,  2.1459,  2.1459,  2.1459],\n",
            "        [ 1.9303,  1.9303,  1.9303,  ...,  2.1459,  2.1459,  2.1459],\n",
            "        [ 1.9303,  1.9303,  1.9303,  ...,  2.1459,  2.1459,  2.1459]]), 'image_grid_thw': tensor([[ 1, 92, 74]]), 'labels': tensor([[151644,   8948,    198,  ...,     92, 151645,    198]])})\n",
            "torch.Size([6808, 1176])\n",
            "torch.Size([1, 5003])\n"
          ]
        }
      ],
      "source": [
        "# Just to sanity check one example\n",
        "batch = next(iter(loader))\n",
        "print(batch.keys())  # should contain input_ids, pixel_values, attention_mask, labels\n",
        "print(batch['pixel_values'].shape)\n",
        "print(batch['input_ids'].shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qn8pxy3qeBIg"
      },
      "source": [
        "## Training Loop - Final Checks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ceXq3jqeAkB"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.optim import AdamW\n",
        "from torch.cuda.amp import autocast\n",
        "from torch.amp import GradScaler\n",
        "from tqdm import tqdm\n",
        "from transformers import get_scheduler\n",
        "import bitsandbytes as bnb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h1BoCWC4eE6H"
      },
      "outputs": [],
      "source": [
        "EPOCHS = 5\n",
        "LR = 2e-5\n",
        "GRADIENT_ACCUM = 8\n",
        "MAX_GRAD_NORM = 1.0\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# ------------------------------\n",
        "# OPTIMIZER AND SCALER\n",
        "# ------------------------------\n",
        "model.train()\n",
        "\n",
        "optimizer = bnb.optim.AdamW8bit(filter(lambda p: p.requires_grad, model.parameters()), lr=LR, weight_decay=0.0)\n",
        "scaler = GradScaler('cuda')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fxeXq8B8RTtS",
        "outputId": "2d265f7b-3533-4565-b80d-03a2c16d72ff",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "base_model.model.model.visual.blocks.0.mlp.gate_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.0.mlp.gate_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.0.mlp.up_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.0.mlp.up_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.0.mlp.down_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.0.mlp.down_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.1.mlp.gate_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.1.mlp.gate_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.1.mlp.up_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.1.mlp.up_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.1.mlp.down_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.1.mlp.down_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.2.mlp.gate_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.2.mlp.gate_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.2.mlp.up_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.2.mlp.up_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.2.mlp.down_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.2.mlp.down_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.3.mlp.gate_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.3.mlp.gate_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.3.mlp.up_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.3.mlp.up_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.3.mlp.down_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.3.mlp.down_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.4.mlp.gate_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.4.mlp.gate_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.4.mlp.up_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.4.mlp.up_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.4.mlp.down_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.4.mlp.down_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.5.mlp.gate_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.5.mlp.gate_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.5.mlp.up_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.5.mlp.up_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.5.mlp.down_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.5.mlp.down_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.6.mlp.gate_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.6.mlp.gate_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.6.mlp.up_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.6.mlp.up_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.6.mlp.down_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.6.mlp.down_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.7.mlp.gate_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.7.mlp.gate_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.7.mlp.up_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.7.mlp.up_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.7.mlp.down_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.7.mlp.down_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.8.mlp.gate_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.8.mlp.gate_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.8.mlp.up_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.8.mlp.up_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.8.mlp.down_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.8.mlp.down_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.9.mlp.gate_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.9.mlp.gate_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.9.mlp.up_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.9.mlp.up_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.9.mlp.down_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.9.mlp.down_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.10.mlp.gate_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.10.mlp.gate_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.10.mlp.up_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.10.mlp.up_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.10.mlp.down_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.10.mlp.down_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.11.mlp.gate_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.11.mlp.gate_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.11.mlp.up_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.11.mlp.up_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.11.mlp.down_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.11.mlp.down_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.12.mlp.gate_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.12.mlp.gate_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.12.mlp.up_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.12.mlp.up_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.12.mlp.down_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.12.mlp.down_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.13.mlp.gate_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.13.mlp.gate_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.13.mlp.up_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.13.mlp.up_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.13.mlp.down_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.13.mlp.down_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.14.mlp.gate_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.14.mlp.gate_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.14.mlp.up_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.14.mlp.up_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.14.mlp.down_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.14.mlp.down_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.15.mlp.gate_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.15.mlp.gate_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.15.mlp.up_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.15.mlp.up_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.15.mlp.down_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.15.mlp.down_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.16.mlp.gate_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.16.mlp.gate_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.16.mlp.up_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.16.mlp.up_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.16.mlp.down_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.16.mlp.down_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.17.mlp.gate_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.17.mlp.gate_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.17.mlp.up_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.17.mlp.up_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.17.mlp.down_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.17.mlp.down_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.18.mlp.gate_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.18.mlp.gate_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.18.mlp.up_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.18.mlp.up_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.18.mlp.down_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.18.mlp.down_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.19.mlp.gate_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.19.mlp.gate_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.19.mlp.up_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.19.mlp.up_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.19.mlp.down_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.19.mlp.down_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.20.mlp.gate_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.20.mlp.gate_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.20.mlp.up_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.20.mlp.up_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.20.mlp.down_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.20.mlp.down_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.21.mlp.gate_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.21.mlp.gate_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.21.mlp.up_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.21.mlp.up_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.21.mlp.down_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.21.mlp.down_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.22.mlp.gate_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.22.mlp.gate_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.22.mlp.up_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.22.mlp.up_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.22.mlp.down_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.22.mlp.down_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.23.mlp.gate_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.23.mlp.gate_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.23.mlp.up_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.23.mlp.up_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.23.mlp.down_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.23.mlp.down_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.24.mlp.gate_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.24.mlp.gate_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.24.mlp.up_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.24.mlp.up_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.24.mlp.down_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.24.mlp.down_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.25.mlp.gate_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.25.mlp.gate_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.25.mlp.up_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.25.mlp.up_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.25.mlp.down_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.25.mlp.down_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.26.mlp.gate_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.26.mlp.gate_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.26.mlp.up_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.26.mlp.up_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.26.mlp.down_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.26.mlp.down_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.27.mlp.gate_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.27.mlp.gate_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.27.mlp.up_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.27.mlp.up_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.27.mlp.down_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.27.mlp.down_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.28.mlp.gate_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.28.mlp.gate_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.28.mlp.up_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.28.mlp.up_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.28.mlp.down_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.28.mlp.down_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.29.mlp.gate_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.29.mlp.gate_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.29.mlp.up_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.29.mlp.up_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.29.mlp.down_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.29.mlp.down_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.30.mlp.gate_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.30.mlp.gate_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.30.mlp.up_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.30.mlp.up_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.30.mlp.down_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.30.mlp.down_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.31.mlp.gate_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.31.mlp.gate_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.31.mlp.up_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.31.mlp.up_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.31.mlp.down_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.visual.blocks.31.mlp.down_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.embed_tokens.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.0.self_attn.q_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.0.self_attn.q_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.0.self_attn.k_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.0.self_attn.k_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.0.self_attn.v_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.0.self_attn.v_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.0.self_attn.o_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.0.self_attn.o_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.0.mlp.gate_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.0.mlp.gate_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.0.mlp.up_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.0.mlp.up_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.0.mlp.down_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.0.mlp.down_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.1.self_attn.q_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.1.self_attn.q_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.1.self_attn.k_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.1.self_attn.k_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.1.self_attn.v_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.1.self_attn.v_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.1.self_attn.o_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.1.self_attn.o_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.1.mlp.gate_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.1.mlp.gate_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.1.mlp.up_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.1.mlp.up_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.1.mlp.down_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.1.mlp.down_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.2.self_attn.q_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.2.self_attn.q_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.2.self_attn.k_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.2.self_attn.k_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.2.self_attn.v_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.2.self_attn.v_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.2.self_attn.o_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.2.self_attn.o_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.2.mlp.gate_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.2.mlp.gate_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.2.mlp.up_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.2.mlp.up_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.2.mlp.down_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.2.mlp.down_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.3.self_attn.q_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.3.self_attn.q_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.3.self_attn.k_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.3.self_attn.k_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.3.self_attn.v_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.3.self_attn.v_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.3.self_attn.o_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.3.self_attn.o_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.3.mlp.gate_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.3.mlp.gate_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.3.mlp.up_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.3.mlp.up_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.3.mlp.down_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.3.mlp.down_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.4.self_attn.q_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.4.self_attn.q_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.4.self_attn.k_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.4.self_attn.k_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.4.self_attn.v_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.4.self_attn.v_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.4.self_attn.o_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.4.self_attn.o_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.4.mlp.gate_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.4.mlp.gate_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.4.mlp.up_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.4.mlp.up_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.4.mlp.down_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.4.mlp.down_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.5.self_attn.q_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.5.self_attn.q_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.5.self_attn.k_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.5.self_attn.k_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.5.self_attn.v_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.5.self_attn.v_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.5.self_attn.o_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.5.self_attn.o_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.5.mlp.gate_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.5.mlp.gate_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.5.mlp.up_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.5.mlp.up_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.5.mlp.down_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.5.mlp.down_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.6.self_attn.q_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.6.self_attn.q_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.6.self_attn.k_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.6.self_attn.k_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.6.self_attn.v_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.6.self_attn.v_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.6.self_attn.o_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.6.self_attn.o_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.6.mlp.gate_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.6.mlp.gate_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.6.mlp.up_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.6.mlp.up_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.6.mlp.down_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.6.mlp.down_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.7.self_attn.q_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.7.self_attn.q_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.7.self_attn.k_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.7.self_attn.k_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.7.self_attn.v_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.7.self_attn.v_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.7.self_attn.o_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.7.self_attn.o_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.7.mlp.gate_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.7.mlp.gate_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.7.mlp.up_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.7.mlp.up_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.7.mlp.down_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.7.mlp.down_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.8.self_attn.q_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.8.self_attn.q_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.8.self_attn.k_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.8.self_attn.k_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.8.self_attn.v_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.8.self_attn.v_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.8.self_attn.o_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.8.self_attn.o_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.8.mlp.gate_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.8.mlp.gate_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.8.mlp.up_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.8.mlp.up_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.8.mlp.down_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.8.mlp.down_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.9.self_attn.q_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.9.self_attn.q_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.9.self_attn.k_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.9.self_attn.k_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.9.self_attn.v_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.9.self_attn.v_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.9.self_attn.o_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.9.self_attn.o_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.9.mlp.gate_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.9.mlp.gate_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.9.mlp.up_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.9.mlp.up_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.9.mlp.down_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.9.mlp.down_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.10.self_attn.q_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.10.self_attn.q_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.10.self_attn.k_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.10.self_attn.k_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.10.self_attn.v_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.10.self_attn.v_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.10.self_attn.o_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.10.self_attn.o_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.10.mlp.gate_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.10.mlp.gate_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.10.mlp.up_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.10.mlp.up_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.10.mlp.down_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.10.mlp.down_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.11.self_attn.q_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.11.self_attn.q_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.11.self_attn.k_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.11.self_attn.k_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.11.self_attn.v_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.11.self_attn.v_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.11.self_attn.o_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.11.self_attn.o_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.11.mlp.gate_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.11.mlp.gate_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.11.mlp.up_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.11.mlp.up_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.11.mlp.down_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.11.mlp.down_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.12.self_attn.q_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.12.self_attn.q_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.12.self_attn.k_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.12.self_attn.k_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.12.self_attn.v_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.12.self_attn.v_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.12.self_attn.o_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.12.self_attn.o_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.12.mlp.gate_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.12.mlp.gate_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.12.mlp.up_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.12.mlp.up_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.12.mlp.down_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.12.mlp.down_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.13.self_attn.q_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.13.self_attn.q_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.13.self_attn.k_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.13.self_attn.k_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.13.self_attn.v_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.13.self_attn.v_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.13.self_attn.o_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.13.self_attn.o_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.13.mlp.gate_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.13.mlp.gate_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.13.mlp.up_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.13.mlp.up_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.13.mlp.down_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.13.mlp.down_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.14.self_attn.q_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.14.self_attn.q_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.14.self_attn.k_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.14.self_attn.k_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.14.self_attn.v_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.14.self_attn.v_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.14.self_attn.o_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.14.self_attn.o_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.14.mlp.gate_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.14.mlp.gate_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.14.mlp.up_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.14.mlp.up_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.14.mlp.down_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.14.mlp.down_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.15.self_attn.q_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.15.self_attn.q_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.15.self_attn.k_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.15.self_attn.k_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.15.self_attn.v_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.15.self_attn.v_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.15.self_attn.o_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.15.self_attn.o_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.15.mlp.gate_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.15.mlp.gate_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.15.mlp.up_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.15.mlp.up_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.15.mlp.down_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.15.mlp.down_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.16.self_attn.q_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.16.self_attn.q_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.16.self_attn.k_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.16.self_attn.k_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.16.self_attn.v_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.16.self_attn.v_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.16.self_attn.o_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.16.self_attn.o_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.16.mlp.gate_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.16.mlp.gate_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.16.mlp.up_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.16.mlp.up_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.16.mlp.down_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.16.mlp.down_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.17.self_attn.q_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.17.self_attn.q_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.17.self_attn.k_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.17.self_attn.k_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.17.self_attn.v_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.17.self_attn.v_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.17.self_attn.o_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.17.self_attn.o_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.17.mlp.gate_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.17.mlp.gate_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.17.mlp.up_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.17.mlp.up_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.17.mlp.down_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.17.mlp.down_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.18.self_attn.q_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.18.self_attn.q_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.18.self_attn.k_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.18.self_attn.k_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.18.self_attn.v_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.18.self_attn.v_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.18.self_attn.o_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.18.self_attn.o_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.18.mlp.gate_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.18.mlp.gate_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.18.mlp.up_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.18.mlp.up_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.18.mlp.down_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.18.mlp.down_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.19.self_attn.q_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.19.self_attn.q_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.19.self_attn.k_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.19.self_attn.k_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.19.self_attn.v_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.19.self_attn.v_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.19.self_attn.o_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.19.self_attn.o_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.19.mlp.gate_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.19.mlp.gate_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.19.mlp.up_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.19.mlp.up_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.19.mlp.down_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.19.mlp.down_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.20.self_attn.q_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.20.self_attn.q_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.20.self_attn.k_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.20.self_attn.k_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.20.self_attn.v_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.20.self_attn.v_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.20.self_attn.o_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.20.self_attn.o_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.20.mlp.gate_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.20.mlp.gate_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.20.mlp.up_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.20.mlp.up_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.20.mlp.down_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.20.mlp.down_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.21.self_attn.q_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.21.self_attn.q_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.21.self_attn.k_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.21.self_attn.k_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.21.self_attn.v_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.21.self_attn.v_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.21.self_attn.o_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.21.self_attn.o_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.21.mlp.gate_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.21.mlp.gate_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.21.mlp.up_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.21.mlp.up_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.21.mlp.down_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.21.mlp.down_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.22.self_attn.q_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.22.self_attn.q_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.22.self_attn.k_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.22.self_attn.k_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.22.self_attn.v_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.22.self_attn.v_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.22.self_attn.o_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.22.self_attn.o_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.22.mlp.gate_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.22.mlp.gate_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.22.mlp.up_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.22.mlp.up_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.22.mlp.down_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.22.mlp.down_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.23.self_attn.q_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.23.self_attn.q_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.23.self_attn.k_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.23.self_attn.k_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.23.self_attn.v_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.23.self_attn.v_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.23.self_attn.o_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.23.self_attn.o_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.23.mlp.gate_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.23.mlp.gate_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.23.mlp.up_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.23.mlp.up_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.23.mlp.down_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.23.mlp.down_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.24.self_attn.q_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.24.self_attn.q_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.24.self_attn.k_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.24.self_attn.k_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.24.self_attn.v_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.24.self_attn.v_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.24.self_attn.o_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.24.self_attn.o_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.24.mlp.gate_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.24.mlp.gate_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.24.mlp.up_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.24.mlp.up_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.24.mlp.down_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.24.mlp.down_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.25.self_attn.q_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.25.self_attn.q_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.25.self_attn.k_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.25.self_attn.k_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.25.self_attn.v_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.25.self_attn.v_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.25.self_attn.o_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.25.self_attn.o_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.25.mlp.gate_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.25.mlp.gate_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.25.mlp.up_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.25.mlp.up_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.25.mlp.down_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.25.mlp.down_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.26.self_attn.q_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.26.self_attn.q_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.26.self_attn.k_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.26.self_attn.k_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.26.self_attn.v_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.26.self_attn.v_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.26.self_attn.o_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.26.self_attn.o_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.26.mlp.gate_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.26.mlp.gate_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.26.mlp.up_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.26.mlp.up_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.26.mlp.down_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.26.mlp.down_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.27.self_attn.q_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.27.self_attn.q_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.27.self_attn.k_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.27.self_attn.k_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.27.self_attn.v_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.27.self_attn.v_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.27.self_attn.o_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.27.self_attn.o_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.27.mlp.gate_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.27.mlp.gate_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.27.mlp.up_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.27.mlp.up_proj.lora_B.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.27.mlp.down_proj.lora_A.default.weight cuda:0 torch.float32\n",
            "base_model.model.model.language_model.layers.27.mlp.down_proj.lora_B.default.weight cuda:0 torch.float32\n"
          ]
        }
      ],
      "source": [
        "for name, p in model.named_parameters():\n",
        "    if p.requires_grad:\n",
        "        print(name, p.device, p.dtype)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kOhASEP1zuqc",
        "outputId": "c750ed60-ec74-4cb4-c59c-c0077dc661e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Checking Layer: Embedding(152064, 3584)\n",
            "\n",
            "Example Weight Value: -0.01708984375\n",
            "Gradients Enabled: True\n",
            "\n",
            " SUCCESS: Gradients are TRUE. The model is fine.\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "try:\n",
        "    # 1. Access the Input Embeddings\n",
        "    # For Qwen, this is usually model.model.model.embed_tokens or similar\n",
        "    input_embeddings = model.get_input_embeddings()\n",
        "\n",
        "    print(f\"Checking Layer: {input_embeddings}\")\n",
        "\n",
        "    # 2. Check the Status\n",
        "    status = input_embeddings.weight.requires_grad\n",
        "    print(f\"\\nExample Weight Value: {input_embeddings.weight[0][0].item()}\")\n",
        "    print(f\"Gradients Enabled: {status}\")\n",
        "\n",
        "    if status == False:\n",
        "        print(\"\\n CRITICAL FAIL: Gradients are FALSE. The model cannot learn properly.\")\n",
        "    else:\n",
        "        print(\"\\n SUCCESS: Gradients are TRUE. The model is fine.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error checking gradients: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zlly-UZfzuqc",
        "outputId": "040d2004-05c6-408f-82f2-1c40b8ebe529"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Searching for Embedding layer to unlock...\n",
            " Found Embedding Layer at: base_model.model.model.language_model.embed_tokens\n",
            "    FORCE SUCCESS: base_model.model.model.language_model.embed_tokens.weight.requires_grad is now TRUE\n"
          ]
        }
      ],
      "source": [
        "def brute_force_enable_grads(module):\n",
        "    found = False\n",
        "    print(\"Searching for Embedding layer to unlock...\")\n",
        "\n",
        "    # Walk through every single submodule\n",
        "    for name, child in module.named_modules():\n",
        "        if isinstance(child, torch.nn.Embedding):\n",
        "            print(f\" Found Embedding Layer at: {name}\")\n",
        "\n",
        "            # FORCE IT: Use the in-place underscore method\n",
        "            child.weight.requires_grad_(True)\n",
        "\n",
        "            # Double check\n",
        "            if child.weight.requires_grad:\n",
        "                print(f\"    FORCE SUCCESS: {name}.weight.requires_grad is now TRUE\")\n",
        "                found = True\n",
        "            else:\n",
        "                print(f\"    FORCE FAILED: {name} is locked.\")\n",
        "\n",
        "    return found\n",
        "\n",
        "# Execute the force fix\n",
        "brute_force_enable_grads(model)\n",
        "\n",
        "# Re-enable checkpointing just in case\n",
        "model.gradient_checkpointing_enable()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A44Wyk0Zzuqc",
        "outputId": "912681f7-4896-42c5-cb46-01ff42c5ffc8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing Data Loader...\n",
            "\n",
            "Checking Path: /workspace/m2w_i_local/401c4e6f-6b0b-47b4-8157-92d7ca468bbc.jpeg\n",
            " File exists on disk.\n",
            "   Size: 243.09 KB\n",
            " Image loaded and has content (not pure black).\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# 1. Get a single batch from your loader\n",
        "print(\"Testing Data Loader...\")\n",
        "iterator = iter(loader)\n",
        "messages = next(iterator) # Uses your collation logic implicitly via loader\n",
        "\n",
        "# 2. Dig into the raw dataset to check the first image path\n",
        "raw_sample = dataset.samples[0]\n",
        "img_path = raw_sample[\"_image_path\"]\n",
        "print(f\"\\nChecking Path: {img_path}\")\n",
        "\n",
        "if os.path.exists(img_path):\n",
        "    print(\" File exists on disk.\")\n",
        "    file_size = os.path.getsize(img_path)\n",
        "    print(f\"   Size: {file_size/1024:.2f} KB\")\n",
        "    if file_size < 1000:\n",
        "        print(\" WARNING: File is suspiciously small.\")\n",
        "else:\n",
        "    print(\" ERROR: File does NOT exist. The model is seeing Black Images.\")\n",
        "\n",
        "# 3. Check what the dataset actually returned\n",
        "# We act like __getitem__ to see if the try/except block triggered\n",
        "try:\n",
        "    img = Image.open(img_path).convert(\"RGB\")\n",
        "    # check if it's all black\n",
        "    extrema = img.getextrema()\n",
        "    if extrema == ((0, 0), (0, 0), (0, 0)):\n",
        "        print(\" Image is completely BLACK (0,0,0).\")\n",
        "    else:\n",
        "        print(\" Image loaded and has content (not pure black).\")\n",
        "except Exception as e:\n",
        "    print(f\" Exception during load: {e}\")\n",
        "    print(\"   The model is falling back to the Black Image.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sVszqdnCzuqc"
      },
      "source": [
        "## Main Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fikwYmlb0ZDc"
      },
      "outputs": [],
      "source": [
        "total_training_steps = (len(loader) // GRADIENT_ACCUM + 1) * EPOCHS\n",
        "scheduler = get_scheduler(\n",
        "    \"linear\",\n",
        "    optimizer=optimizer,\n",
        "    num_warmup_steps=int(0.03 * total_training_steps),  # 3% warmup\n",
        "    num_training_steps=total_training_steps\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UTLbrDNk0WZ8",
        "outputId": "db1e3819-1fe2-4c45-8bd6-50c6f84bded2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "No checkpoint found. Starting training from scratch.\n",
            "\n",
            "=== Epoch 1/5 ===\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1:   0%|          | 0/5743 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "Epoch 1:   1%|         | 80/5743 [08:20<9:40:12,  6.15s/it] "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 10, Avg Loss: 11.8598\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1:   3%|         | 160/5743 [16:05<8:33:40,  5.52s/it] "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 20, Avg Loss: 12.6567\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1:   4%|         | 240/5743 [24:01<12:26:55,  8.14s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 30, Avg Loss: 9.9371\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1:   6%|         | 320/5743 [32:13<9:25:57,  6.26s/it] "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 40, Avg Loss: 7.5943\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1:   7%|         | 400/5743 [40:21<8:57:07,  6.03s/it] "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 50, Avg Loss: 6.7472\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1:   8%|         | 480/5743 [48:40<9:29:49,  6.50s/it] "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 60, Avg Loss: 6.3296\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1:  10%|         | 560/5743 [57:04<8:47:16,  6.10s/it] "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 70, Avg Loss: 6.2116\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1:  11%|         | 640/5743 [1:04:59<8:30:39,  6.00s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 80, Avg Loss: 4.9128\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1:  13%|        | 720/5743 [1:12:59<7:00:42,  5.03s/it] "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 90, Avg Loss: 4.6783\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1:  14%|        | 800/5743 [1:21:36<9:52:08,  7.19s/it] "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 100, Avg Loss: 3.2585\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1:  15%|        | 880/5743 [1:29:42<8:06:41,  6.00s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 110, Avg Loss: 4.3855\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1:  17%|        | 960/5743 [1:38:04<6:25:39,  4.84s/it] "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 120, Avg Loss: 4.2634\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1:  18%|        | 1040/5743 [1:45:46<10:39:26,  8.16s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 130, Avg Loss: 2.2563\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1:  20%|        | 1120/5743 [1:53:54<8:20:30,  6.50s/it] "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 140, Avg Loss: 3.5343\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1:  21%|        | 1200/5743 [2:01:48<6:20:10,  5.02s/it] "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 150, Avg Loss: 5.3593\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1:  22%|       | 1280/5743 [2:10:01<7:43:26,  6.23s/it] "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 160, Avg Loss: 3.3688\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1:  24%|       | 1360/5743 [2:17:59<7:50:37,  6.44s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 170, Avg Loss: 4.2380\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1:  25%|       | 1440/5743 [2:26:15<8:07:19,  6.80s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 180, Avg Loss: 2.8666\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1:  26%|       | 1520/5743 [2:34:29<7:24:38,  6.32s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 190, Avg Loss: 3.4646\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1:  28%|       | 1599/5743 [2:42:28<6:59:15,  6.07s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 200, Avg Loss: 2.4319\n",
            "\n",
            "Saving checkpoint at step 200...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1:  28%|       | 1600/5743 [2:42:44<10:13:06,  8.88s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Checkpoint saved to /workspace/qwen_checkpoints/step_200\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1:  29%|       | 1680/5743 [2:51:15<6:21:08,  5.63s/it] "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 210, Avg Loss: 2.8790\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1:  31%|       | 1760/5743 [2:59:14<7:32:44,  6.82s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 220, Avg Loss: 3.1580\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1:  32%|      | 1840/5743 [3:07:07<7:06:46,  6.56s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 230, Avg Loss: 2.8019\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1:  33%|      | 1920/5743 [3:15:32<7:12:37,  6.79s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 240, Avg Loss: 3.1003\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1:  35%|      | 2000/5743 [3:23:26<6:22:50,  6.14s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 250, Avg Loss: 4.1242\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1:  36%|      | 2080/5743 [3:31:57<6:19:44,  6.22s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 260, Avg Loss: 2.6549\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1:  38%|      | 2160/5743 [3:40:24<5:44:56,  5.78s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 270, Avg Loss: 3.4153\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1:  39%|      | 2240/5743 [3:48:28<4:47:50,  4.93s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 280, Avg Loss: 3.9048\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1:  40%|      | 2320/5743 [3:56:22<5:32:30,  5.83s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 290, Avg Loss: 2.7044\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1:  42%|     | 2400/5743 [4:04:32<5:48:29,  6.25s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 300, Avg Loss: 2.8065\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1:  43%|     | 2480/5743 [4:12:45<5:58:52,  6.60s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 310, Avg Loss: 1.9484\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1:  45%|     | 2560/5743 [4:20:44<5:46:42,  6.54s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 320, Avg Loss: 2.7376\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1:  46%|     | 2640/5743 [4:29:00<5:53:06,  6.83s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 330, Avg Loss: 2.9554\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1:  47%|     | 2720/5743 [4:36:44<4:29:20,  5.35s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 340, Avg Loss: 3.2163\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1:  49%|     | 2800/5743 [4:45:05<4:33:38,  5.58s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 350, Avg Loss: 5.1988\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1:  50%|     | 2880/5743 [4:53:06<5:30:16,  6.92s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 360, Avg Loss: 2.9823\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1:  52%|    | 2960/5743 [5:01:07<3:52:25,  5.01s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 370, Avg Loss: 4.9398\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1:  53%|    | 3040/5743 [5:09:41<5:03:29,  6.74s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 380, Avg Loss: 2.6730\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1:  54%|    | 3120/5743 [5:17:41<4:56:44,  6.79s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 390, Avg Loss: 2.6407\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1:  56%|    | 3199/5743 [5:25:39<3:11:05,  4.51s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 400, Avg Loss: 3.8453\n",
            "\n",
            "Saving checkpoint at step 400...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1:  56%|    | 3200/5743 [5:25:50<4:28:12,  6.33s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Checkpoint saved to /workspace/qwen_checkpoints/step_400\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1:  57%|    | 3280/5743 [5:33:36<4:20:29,  6.35s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 410, Avg Loss: 3.6292\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1:  59%|    | 3360/5743 [5:41:47<4:24:07,  6.65s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 420, Avg Loss: 2.4536\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1:  60%|    | 3440/5743 [5:49:50<3:57:10,  6.18s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 430, Avg Loss: 3.1114\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1:  61%|   | 3520/5743 [5:58:24<4:29:06,  7.26s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 440, Avg Loss: 2.8604\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1:  63%|   | 3600/5743 [6:06:39<3:15:58,  5.49s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 450, Avg Loss: 3.0112\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1:  64%|   | 3680/5743 [6:15:15<4:25:26,  7.72s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 460, Avg Loss: 2.2722\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1:  65%|   | 3760/5743 [6:23:50<3:33:52,  6.47s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 470, Avg Loss: 2.9005\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1:  67%|   | 3840/5743 [6:32:06<3:23:03,  6.40s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 480, Avg Loss: 2.6805\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1:  68%|   | 3920/5743 [6:40:23<3:15:19,  6.43s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 490, Avg Loss: 2.9653\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1:  70%|   | 4000/5743 [6:48:36<2:41:47,  5.57s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 500, Avg Loss: 3.2010\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1:  71%|   | 4080/5743 [6:56:53<2:45:22,  5.97s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 510, Avg Loss: 5.1837\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1:  72%|  | 4160/5743 [7:05:14<3:23:32,  7.72s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 520, Avg Loss: 3.0395\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1:  74%|  | 4240/5743 [7:13:00<1:45:48,  4.22s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 530, Avg Loss: 5.5101\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1:  75%|  | 4320/5743 [7:21:42<2:43:04,  6.88s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 540, Avg Loss: 3.1214\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1:  77%|  | 4400/5743 [7:30:16<2:29:22,  6.67s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 550, Avg Loss: 2.6693\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1:  78%|  | 4480/5743 [7:38:46<2:22:50,  6.79s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 560, Avg Loss: 2.8058\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1:  79%|  | 4560/5743 [7:47:08<2:09:13,  6.55s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 570, Avg Loss: 3.1186\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1:  81%|  | 4640/5743 [7:55:16<2:03:24,  6.71s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 580, Avg Loss: 3.3163\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1:  82%| | 4720/5743 [8:03:33<1:41:44,  5.97s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 590, Avg Loss: 4.1122\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1:  84%| | 4799/5743 [8:11:21<1:27:44,  5.58s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 600, Avg Loss: 4.0709\n",
            "\n",
            "Saving checkpoint at step 600...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1:  84%| | 4800/5743 [8:11:32<1:51:40,  7.11s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Checkpoint saved to /workspace/qwen_checkpoints/step_600\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1:  85%| | 4880/5743 [8:19:14<1:35:58,  6.67s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 610, Avg Loss: 3.0389\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1:  86%| | 4960/5743 [8:27:26<1:19:56,  6.13s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 620, Avg Loss: 3.4355\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1:  88%| | 5040/5743 [8:35:42<1:12:38,  6.20s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 630, Avg Loss: 3.2800\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1:  89%| | 5120/5743 [8:43:46<1:03:58,  6.16s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 640, Avg Loss: 3.2897\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1:  91%| | 5200/5743 [8:52:02<57:00,  6.30s/it]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 650, Avg Loss: 2.4887\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1:  92%|| 5280/5743 [9:00:25<51:32,  6.68s/it]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 660, Avg Loss: 2.8903\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1:  93%|| 5360/5743 [9:08:40<45:51,  7.18s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 670, Avg Loss: 2.8769\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1:  95%|| 5440/5743 [9:16:54<28:36,  5.66s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 680, Avg Loss: 4.1884\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1:  96%|| 5520/5743 [9:25:06<23:39,  6.36s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 690, Avg Loss: 4.0289\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1:  98%|| 5600/5743 [9:33:16<13:55,  5.84s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 700, Avg Loss: 2.8469\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1:  99%|| 5680/5743 [9:41:09<06:59,  6.66s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 710, Avg Loss: 2.8578\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1: 100%|| 5743/5743 [9:47:42<00:00,  6.14s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Epoch 2/5 ===\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2:   0%|          | 24/5743 [02:29<8:19:00,  5.24s/it] "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 720, Avg Loss: 4.6998\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2:   2%|         | 104/5743 [10:29<8:20:15,  5.32s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 730, Avg Loss: 2.6421\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2:   3%|         | 184/5743 [18:31<7:27:22,  4.83s/it] "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 740, Avg Loss: 4.8358\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2:   5%|         | 264/5743 [26:02<8:29:30,  5.58s/it] "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 750, Avg Loss: 2.9842\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2:   6%|         | 344/5743 [34:17<9:54:58,  6.61s/it] "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 760, Avg Loss: 3.5088\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2:   7%|         | 424/5743 [42:25<8:18:39,  5.62s/it] "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 770, Avg Loss: 6.4071\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2:   9%|         | 504/5743 [50:09<7:51:25,  5.40s/it] "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 780, Avg Loss: 4.3003\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2:  10%|         | 584/5743 [58:13<7:38:13,  5.33s/it] "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 790, Avg Loss: 2.3623\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2:  12%|        | 663/5743 [1:06:24<8:26:16,  5.98s/it] "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 800, Avg Loss: 3.0282\n",
            "\n",
            "Saving checkpoint at step 800...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2:  12%|        | 664/5743 [1:06:37<11:31:12,  8.17s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Checkpoint saved to /workspace/qwen_checkpoints/step_800\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2:  13%|        | 744/5743 [1:14:57<10:05:25,  7.27s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 810, Avg Loss: 2.1934\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2:  14%|        | 824/5743 [1:23:06<9:21:12,  6.85s/it] "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 820, Avg Loss: 2.5205\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2:  16%|        | 904/5743 [1:31:50<7:30:07,  5.58s/it] "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 830, Avg Loss: 3.6800\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2:  17%|        | 984/5743 [1:39:59<8:46:48,  6.64s/it] "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 840, Avg Loss: 2.5660\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2:  19%|        | 1064/5743 [1:48:51<8:17:24,  6.38s/it] "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 850, Avg Loss: 3.1041\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2:  20%|        | 1144/5743 [1:57:15<7:56:18,  6.21s/it] "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 860, Avg Loss: 2.6794\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2:  21%|       | 1224/5743 [2:05:22<7:19:09,  5.83s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 870, Avg Loss: 2.9308\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2:  23%|       | 1304/5743 [2:13:42<8:11:35,  6.64s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 880, Avg Loss: 2.7755\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2:  24%|       | 1384/5743 [2:21:39<6:01:41,  4.98s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 890, Avg Loss: 5.1399\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2:  25%|       | 1464/5743 [2:29:47<8:43:01,  7.33s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 900, Avg Loss: 2.7992\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2:  27%|       | 1544/5743 [2:37:44<6:54:34,  5.92s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 910, Avg Loss: 2.7277\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2:  28%|       | 1624/5743 [2:45:46<6:46:42,  5.92s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 920, Avg Loss: 4.0033\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2:  30%|       | 1704/5743 [2:53:30<5:01:59,  4.49s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 930, Avg Loss: 2.9508\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2:  31%|       | 1784/5743 [3:01:47<7:13:28,  6.57s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 940, Avg Loss: 2.4688\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2:  32%|      | 1864/5743 [3:09:58<7:12:15,  6.69s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 950, Avg Loss: 2.4812\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2:  34%|      | 1944/5743 [3:18:22<6:11:21,  5.87s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 960, Avg Loss: 2.2479\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2:  35%|      | 2024/5743 [3:26:10<6:47:55,  6.58s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 970, Avg Loss: 2.7096\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2:  37%|      | 2104/5743 [3:33:38<5:18:50,  5.26s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 980, Avg Loss: 2.6673\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2:  38%|      | 2184/5743 [3:42:07<7:12:34,  7.29s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 990, Avg Loss: 2.6058\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2:  39%|      | 2263/5743 [3:50:01<6:23:38,  6.61s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 1000, Avg Loss: 2.5231\n",
            "\n",
            "Saving checkpoint at step 1000...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2:  39%|      | 2264/5743 [3:50:15<8:37:20,  8.92s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Checkpoint saved to /workspace/qwen_checkpoints/step_1000\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2:  41%|      | 2344/5743 [3:58:03<6:00:08,  6.36s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 1010, Avg Loss: 3.2321\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2:  42%|     | 2424/5743 [4:05:59<5:24:40,  5.87s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 1020, Avg Loss: 3.5928\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2:  44%|     | 2504/5743 [4:14:10<6:22:16,  7.08s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 1030, Avg Loss: 2.4857\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2:  45%|     | 2584/5743 [4:22:17<5:34:31,  6.35s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 1040, Avg Loss: 2.9284\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2:  46%|     | 2664/5743 [4:30:33<4:44:55,  5.55s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 1050, Avg Loss: 4.0907\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2:  48%|     | 2744/5743 [4:38:21<4:38:19,  5.57s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 1060, Avg Loss: 3.0542\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2:  49%|     | 2824/5743 [4:46:58<4:12:23,  5.19s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 1070, Avg Loss: 6.3601\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2:  51%|     | 2904/5743 [4:55:05<5:17:19,  6.71s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 1080, Avg Loss: 3.1386\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2:  52%|    | 2984/5743 [5:02:47<4:18:29,  5.62s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 1090, Avg Loss: 3.2772\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2:  53%|    | 3064/5743 [5:10:38<4:33:49,  6.13s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 1100, Avg Loss: 2.9637\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2:  55%|    | 3144/5743 [5:18:41<4:28:38,  6.20s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 1110, Avg Loss: 2.9052\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2:  56%|    | 3224/5743 [5:27:03<4:25:26,  6.32s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 1120, Avg Loss: 1.9411\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2:  58%|    | 3304/5743 [5:35:12<4:31:32,  6.68s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 1130, Avg Loss: 2.6017\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2:  59%|    | 3384/5743 [5:43:22<4:03:00,  6.18s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 1140, Avg Loss: 2.8268\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2:  60%|    | 3464/5743 [5:51:30<4:24:21,  6.96s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 1150, Avg Loss: 2.9249\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2:  62%|   | 3544/5743 [5:59:34<3:05:09,  5.05s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 1160, Avg Loss: 3.8155\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2:  63%|   | 3624/5743 [6:07:38<3:05:16,  5.25s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 1170, Avg Loss: 3.2438\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2:  64%|   | 3704/5743 [6:15:54<3:27:00,  6.09s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 1180, Avg Loss: 2.4201\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2:  66%|   | 3784/5743 [6:24:20<4:01:46,  7.41s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 1190, Avg Loss: 2.4750\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2:  67%|   | 3863/5743 [6:32:48<3:37:23,  6.94s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 1200, Avg Loss: 2.7684\n",
            "\n",
            "Saving checkpoint at step 1200...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2:  67%|   | 3864/5743 [6:33:02<4:50:10,  9.27s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Checkpoint saved to /workspace/qwen_checkpoints/step_1200\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2:  69%|   | 3944/5743 [6:41:00<3:32:34,  7.09s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 1210, Avg Loss: 2.6283\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2:  70%|   | 4024/5743 [6:49:08<2:17:47,  4.81s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 1220, Avg Loss: 4.1852\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2:  71%|  | 4104/5743 [6:57:22<2:41:11,  5.90s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 1230, Avg Loss: 2.1782\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2:  73%|  | 4184/5743 [7:05:33<2:56:58,  6.81s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 1240, Avg Loss: 2.8005\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2:  74%|  | 4264/5743 [7:13:49<2:50:01,  6.90s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 1250, Avg Loss: 2.4939\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2:  76%|  | 4344/5743 [7:22:04<2:40:34,  6.89s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 1260, Avg Loss: 2.4558\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2:  77%|  | 4424/5743 [7:30:31<2:38:24,  7.21s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 1270, Avg Loss: 2.4301\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2:  78%|  | 4504/5743 [7:39:02<2:21:22,  6.85s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 1280, Avg Loss: 2.6119\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2:  80%|  | 4584/5743 [7:47:29<2:33:15,  7.93s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 1290, Avg Loss: 2.8913\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2:  81%|  | 4664/5743 [7:55:46<2:16:32,  7.59s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 1300, Avg Loss: 2.5328\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2:  83%| | 4744/5743 [8:03:27<1:41:52,  6.12s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 1310, Avg Loss: 2.8914\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2:  84%| | 4824/5743 [8:11:47<1:22:22,  5.38s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 1320, Avg Loss: 5.3518\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2:  85%| | 4904/5743 [8:20:18<1:15:43,  5.41s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 1330, Avg Loss: 2.8109\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2:  87%| | 4984/5743 [8:28:38<1:23:04,  6.57s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 1340, Avg Loss: 2.8759\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2:  88%| | 5064/5743 [8:37:13<1:27:28,  7.73s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 1350, Avg Loss: 2.1269\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2:  90%| | 5144/5743 [8:45:17<1:06:14,  6.63s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 1360, Avg Loss: 2.7355\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2:  91%| | 5224/5743 [8:53:12<58:47,  6.80s/it]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 1370, Avg Loss: 2.7498\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2:  92%|| 5304/5743 [9:01:42<47:58,  6.56s/it]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 1380, Avg Loss: 2.1663\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2:  94%|| 5384/5743 [9:10:05<33:43,  5.64s/it]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 1390, Avg Loss: 2.4610\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2:  95%|| 5463/5743 [9:17:57<27:25,  5.88s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 1400, Avg Loss: 3.0362\n",
            "\n",
            "Saving checkpoint at step 1400...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2:  95%|| 5464/5743 [9:18:11<37:36,  8.09s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Checkpoint saved to /workspace/qwen_checkpoints/step_1400\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2:  97%|| 5544/5743 [9:26:20<16:54,  5.10s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 1410, Avg Loss: 2.9616\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2:  98%|| 5624/5743 [9:34:34<10:18,  5.20s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 1420, Avg Loss: 2.4890\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2:  99%|| 5704/5743 [9:43:13<04:48,  7.40s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 1430, Avg Loss: 2.7102\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2: 100%|| 5743/5743 [9:47:24<00:00,  6.14s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Epoch 3/5 ===\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3:   1%|          | 48/5743 [04:55<10:39:25,  6.74s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 1440, Avg Loss: 2.7495\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3:   2%|         | 128/5743 [12:59<8:54:52,  5.72s/it] "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 1450, Avg Loss: 2.7525\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3:   4%|         | 208/5743 [20:55<9:31:15,  6.19s/it] "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 1460, Avg Loss: 1.8697\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3:   5%|         | 288/5743 [29:19<8:08:14,  5.37s/it] "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 1470, Avg Loss: 4.6645\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3:   6%|         | 368/5743 [37:44<11:04:29,  7.42s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 1480, Avg Loss: 2.9115\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3:   8%|         | 448/5743 [46:07<9:55:16,  6.75s/it] "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 1490, Avg Loss: 2.5286\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3:   9%|         | 528/5743 [54:49<8:26:57,  5.83s/it] "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 1500, Avg Loss: 2.6924\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3:  11%|         | 608/5743 [1:02:57<8:19:09,  5.83s/it] "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 1510, Avg Loss: 2.8253\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3:  12%|        | 688/5743 [1:10:29<8:19:33,  5.93s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 1520, Avg Loss: 2.5834\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3:  13%|        | 768/5743 [1:18:59<8:36:48,  6.23s/it] "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 1530, Avg Loss: 2.7079\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3:  15%|        | 848/5743 [1:27:03<8:38:30,  6.36s/it] "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 1540, Avg Loss: 2.4522\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3:  16%|        | 928/5743 [1:35:19<7:43:07,  5.77s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 1550, Avg Loss: 3.1809\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3:  18%|        | 1008/5743 [1:43:28<9:47:25,  7.44s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 1560, Avg Loss: 2.4492\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3:  19%|        | 1088/5743 [1:51:43<7:33:33,  5.85s/it] "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 1570, Avg Loss: 2.7264\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3:  20%|        | 1168/5743 [1:59:52<8:31:06,  6.70s/it] "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 1580, Avg Loss: 2.4449\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3:  22%|       | 1248/5743 [2:07:43<6:52:52,  5.51s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 1590, Avg Loss: 2.8307\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3:  23%|       | 1327/5743 [2:15:38<7:10:24,  5.85s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 1600, Avg Loss: 2.4067\n",
            "\n",
            "Saving checkpoint at step 1600...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3:  23%|       | 1328/5743 [2:15:51<9:51:56,  8.04s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Checkpoint saved to /workspace/qwen_checkpoints/step_1600\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3:  25%|       | 1408/5743 [2:24:19<7:32:19,  6.26s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 1610, Avg Loss: 2.8864\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3:  26%|       | 1488/5743 [2:32:19<6:56:05,  5.87s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 1620, Avg Loss: 2.9140\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3:  27%|       | 1568/5743 [2:40:41<7:38:20,  6.59s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 1630, Avg Loss: 2.7877\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3:  29%|       | 1648/5743 [2:49:06<8:12:40,  7.22s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 1640, Avg Loss: 2.5419\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3:  30%|       | 1728/5743 [2:57:11<5:07:41,  4.60s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 1650, Avg Loss: 6.2924\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3:  31%|      | 1808/5743 [3:04:53<5:58:18,  5.46s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 1660, Avg Loss: 3.0154\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3:  33%|      | 1888/5743 [3:13:01<7:08:44,  6.67s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 1670, Avg Loss: 2.4759\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3:  34%|      | 1968/5743 [3:20:59<6:57:07,  6.63s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 1680, Avg Loss: 2.3723\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3:  36%|      | 2048/5743 [3:28:58<5:47:17,  5.64s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 1690, Avg Loss: 2.2706\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3:  37%|      | 2128/5743 [3:37:09<6:45:53,  6.74s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 1700, Avg Loss: 2.5722\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3:  38%|      | 2208/5743 [3:44:36<5:18:41,  5.41s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 1710, Avg Loss: 3.5846\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3:  40%|      | 2288/5743 [3:53:15<6:25:35,  6.70s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 1720, Avg Loss: 2.6077\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3:  41%|      | 2368/5743 [4:01:36<4:23:41,  4.69s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 1730, Avg Loss: 3.0560\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3:  43%|     | 2448/5743 [4:09:48<6:07:31,  6.69s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 1740, Avg Loss: 2.5211\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3:  44%|     | 2528/5743 [4:17:49<6:14:31,  6.99s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 1750, Avg Loss: 2.8103\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3:  45%|     | 2608/5743 [4:25:37<4:50:13,  5.55s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 1760, Avg Loss: 2.5532\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3:  47%|     | 2688/5743 [4:33:44<5:20:59,  6.30s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 1770, Avg Loss: 2.4307\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3:  48%|     | 2768/5743 [4:41:54<4:38:03,  5.61s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 1780, Avg Loss: 2.8211\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3:  50%|     | 2848/5743 [4:50:02<5:17:25,  6.58s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 1790, Avg Loss: 2.4691\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3:  51%|     | 2927/5743 [4:57:56<4:47:18,  6.12s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 1800, Avg Loss: 2.7050\n",
            "\n",
            "Saving checkpoint at step 1800...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3:  51%|     | 2928/5743 [4:58:10<6:40:43,  8.54s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Checkpoint saved to /workspace/qwen_checkpoints/step_1800\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3:  52%|    | 3008/5743 [5:06:18<3:41:38,  4.86s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 1810, Avg Loss: 4.6809\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3:  54%|    | 3088/5743 [5:15:16<4:57:55,  6.73s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 1820, Avg Loss: 3.3686\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3:  55%|    | 3168/5743 [5:23:46<4:22:22,  6.11s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 1830, Avg Loss: 2.2844\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3:  57%|    | 3248/5743 [5:31:58<3:59:38,  5.76s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 1840, Avg Loss: 2.4089\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3:  58%|    | 3328/5743 [5:40:05<4:28:36,  6.67s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 1850, Avg Loss: 2.5291\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3:  59%|    | 3408/5743 [5:47:54<5:03:15,  7.79s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 1860, Avg Loss: 2.1519\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3:  61%|    | 3488/5743 [5:56:28<3:36:20,  5.76s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 1870, Avg Loss: 4.1201\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3:  62%|   | 3568/5743 [6:04:20<3:45:33,  6.22s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 1880, Avg Loss: 2.7861\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3:  64%|   | 3648/5743 [6:12:29<3:50:06,  6.59s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 1890, Avg Loss: 2.6136\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3:  65%|   | 3728/5743 [6:21:09<4:07:28,  7.37s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 1900, Avg Loss: 2.6613\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3:  66%|   | 3808/5743 [6:29:09<3:30:46,  6.54s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 1910, Avg Loss: 2.2966\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3:  68%|   | 3888/5743 [6:37:08<3:10:18,  6.16s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 1920, Avg Loss: 2.2789\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3:  69%|   | 3968/5743 [6:45:19<2:42:53,  5.51s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 1930, Avg Loss: 5.0505\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3:  70%|   | 4048/5743 [6:53:38<3:02:05,  6.45s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 1940, Avg Loss: 2.8559\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3:  72%|  | 4128/5743 [7:01:31<2:45:32,  6.15s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 1950, Avg Loss: 1.8422\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3:  73%|  | 4208/5743 [7:09:50<2:41:36,  6.32s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 1960, Avg Loss: 2.7722\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3:  75%|  | 4288/5743 [7:17:58<2:40:47,  6.63s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 1970, Avg Loss: 2.1142\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3:  76%|  | 4368/5743 [7:25:51<2:20:48,  6.14s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 1980, Avg Loss: 2.1810\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3:  77%|  | 4448/5743 [7:34:01<2:30:49,  6.99s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 1990, Avg Loss: 2.5862\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3:  79%|  | 4527/5743 [7:41:51<1:49:03,  5.38s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 2000, Avg Loss: 4.5001\n",
            "\n",
            "Saving checkpoint at step 2000...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3:  79%|  | 4528/5743 [7:42:02<2:24:31,  7.14s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Checkpoint saved to /workspace/qwen_checkpoints/step_2000\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3:  80%|  | 4608/5743 [7:50:21<1:53:33,  6.00s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 2010, Avg Loss: 4.4513\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3:  82%| | 4688/5743 [7:58:39<1:37:00,  5.52s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 2020, Avg Loss: 2.6396\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3:  83%| | 4768/5743 [8:06:13<1:45:25,  6.49s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 2030, Avg Loss: 2.6277\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3:  84%| | 4848/5743 [8:14:20<1:29:36,  6.01s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 2040, Avg Loss: 2.5748\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3:  86%| | 4928/5743 [8:22:48<1:31:12,  6.71s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 2050, Avg Loss: 2.8333\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3:  87%| | 5008/5743 [8:31:06<1:14:07,  6.05s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 2060, Avg Loss: 2.9946\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3:  89%| | 5088/5743 [8:39:47<1:18:00,  7.15s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 2070, Avg Loss: 2.1627\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3:  90%| | 5168/5743 [8:48:09<56:37,  5.91s/it]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 2080, Avg Loss: 2.3491\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3:  91%|| 5248/5743 [8:56:41<54:13,  6.57s/it]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 2090, Avg Loss: 2.9356\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3:  93%|| 5328/5743 [9:04:53<55:58,  8.09s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 2100, Avg Loss: 2.6007\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3:  94%|| 5408/5743 [9:13:01<27:55,  5.00s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 2110, Avg Loss: 2.7437\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3:  96%|| 5488/5743 [9:21:20<23:02,  5.42s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 2120, Avg Loss: 4.0167\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3:  97%|| 5568/5743 [9:29:20<17:52,  6.13s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 2130, Avg Loss: 2.7724\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3:  98%|| 5648/5743 [9:37:45<11:24,  7.21s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 2140, Avg Loss: 2.3556\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3: 100%|| 5728/5743 [9:45:47<01:13,  4.92s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 2150, Avg Loss: 3.5977\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3: 100%|| 5743/5743 [9:47:21<00:00,  6.14s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Epoch 4/5 ===\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4:   1%|         | 72/5743 [07:08<8:34:09,  5.44s/it] "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 2160, Avg Loss: 4.2026\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4:   3%|         | 152/5743 [14:44<9:03:36,  5.83s/it] "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 2170, Avg Loss: 3.5186\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4:   4%|         | 232/5743 [23:15<9:49:21,  6.42s/it] "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 2180, Avg Loss: 2.5311\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4:   5%|         | 312/5743 [31:11<8:14:10,  5.46s/it] "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 2190, Avg Loss: 5.3522\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4:   7%|         | 391/5743 [39:26<8:13:35,  5.53s/it] "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 2200, Avg Loss: 2.5714\n",
            "\n",
            "Saving checkpoint at step 2200...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4:   7%|         | 392/5743 [39:42<12:32:43,  8.44s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Checkpoint saved to /workspace/qwen_checkpoints/step_2200\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4:   8%|         | 472/5743 [48:14<9:20:44,  6.38s/it] "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 2210, Avg Loss: 2.7229\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4:  10%|         | 552/5743 [56:35<9:42:14,  6.73s/it] "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 2220, Avg Loss: 2.7683\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4:  11%|         | 632/5743 [1:04:41<8:01:06,  5.65s/it] "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 2230, Avg Loss: 1.8849\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4:  12%|        | 712/5743 [1:12:36<8:41:15,  6.22s/it] "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 2240, Avg Loss: 2.4830\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4:  14%|        | 792/5743 [1:21:07<9:58:52,  7.26s/it] "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 2250, Avg Loss: 2.9251\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4:  15%|        | 872/5743 [1:29:15<8:34:59,  6.34s/it] "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 2260, Avg Loss: 3.6907\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4:  17%|        | 952/5743 [1:37:02<6:36:44,  4.97s/it] "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 2270, Avg Loss: 4.4459\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4:  18%|        | 1032/5743 [1:44:56<8:17:56,  6.34s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 2280, Avg Loss: 2.7070\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4:  19%|        | 1112/5743 [1:52:40<8:04:26,  6.28s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 2290, Avg Loss: 2.9102\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4:  21%|        | 1192/5743 [2:01:03<7:06:59,  5.63s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 2300, Avg Loss: 3.8778\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4:  22%|       | 1272/5743 [2:09:00<7:37:07,  6.13s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 2310, Avg Loss: 2.7282\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4:  24%|       | 1352/5743 [2:17:37<8:59:47,  7.38s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 2320, Avg Loss: 2.4633\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4:  25%|       | 1432/5743 [2:25:59<9:34:27,  8.00s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 2330, Avg Loss: 2.4547\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4:  26%|       | 1512/5743 [2:34:19<6:33:15,  5.58s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 2340, Avg Loss: 2.8814\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4:  28%|       | 1592/5743 [2:42:06<8:00:22,  6.94s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 2350, Avg Loss: 2.2680\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4:  29%|       | 1672/5743 [2:50:39<7:49:15,  6.92s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 2360, Avg Loss: 2.6801\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4:  31%|       | 1752/5743 [2:59:07<6:59:51,  6.31s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 2370, Avg Loss: 2.9751\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4:  32%|      | 1832/5743 [3:07:03<7:19:29,  6.74s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 2380, Avg Loss: 2.4725\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4:  33%|      | 1912/5743 [3:15:30<6:16:10,  5.89s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 2390, Avg Loss: 2.2747\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4:  35%|      | 1991/5743 [3:24:13<7:05:05,  6.80s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 2400, Avg Loss: 2.8120\n",
            "\n",
            "Saving checkpoint at step 2400...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4:  35%|      | 1992/5743 [3:24:26<9:09:27,  8.79s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Checkpoint saved to /workspace/qwen_checkpoints/step_2400\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4:  36%|      | 2072/5743 [3:32:29<6:59:26,  6.86s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 2410, Avg Loss: 2.7566\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4:  37%|      | 2152/5743 [3:40:31<6:40:41,  6.69s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 2420, Avg Loss: 2.1611\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4:  39%|      | 2232/5743 [3:48:49<5:52:06,  6.02s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 2430, Avg Loss: 2.2469\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4:  40%|      | 2312/5743 [3:57:10<5:53:56,  6.19s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 2440, Avg Loss: 2.6148\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4:  42%|     | 2392/5743 [4:05:13<6:18:38,  6.78s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 2450, Avg Loss: 2.4404\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4:  43%|     | 2472/5743 [4:13:26<5:42:02,  6.27s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 2460, Avg Loss: 2.2136\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4:  44%|     | 2552/5743 [4:21:39<6:04:38,  6.86s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 2470, Avg Loss: 2.3240\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4:  46%|     | 2632/5743 [4:29:30<4:35:56,  5.32s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 2480, Avg Loss: 4.2045\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4:  47%|     | 2712/5743 [4:37:28<6:16:40,  7.46s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 2490, Avg Loss: 2.0385\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4:  49%|     | 2792/5743 [4:45:32<4:56:43,  6.03s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 2500, Avg Loss: 2.6226\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4:  50%|     | 2872/5743 [4:53:57<4:06:05,  5.14s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 2510, Avg Loss: 4.7390\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4:  51%|    | 2952/5743 [5:01:55<3:58:44,  5.13s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 2520, Avg Loss: 3.5708\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4:  53%|    | 3032/5743 [5:09:51<5:01:24,  6.67s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 2530, Avg Loss: 2.5463\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4:  54%|    | 3112/5743 [5:18:08<4:34:42,  6.26s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 2540, Avg Loss: 3.6018\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4:  56%|    | 3192/5743 [5:26:20<4:02:17,  5.70s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 2550, Avg Loss: 2.3405\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4:  57%|    | 3272/5743 [5:34:16<3:51:43,  5.63s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 2560, Avg Loss: 4.2159\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4:  58%|    | 3352/5743 [5:42:24<3:51:07,  5.80s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 2570, Avg Loss: 2.8546\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4:  60%|    | 3432/5743 [5:50:42<4:48:59,  7.50s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 2580, Avg Loss: 2.1166\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4:  61%|    | 3512/5743 [5:58:40<4:15:08,  6.86s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 2590, Avg Loss: 2.8049\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4:  63%|   | 3591/5743 [6:06:47<3:10:55,  5.32s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 2600, Avg Loss: 2.6839\n",
            "\n",
            "Saving checkpoint at step 2600...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4:  63%|   | 3592/5743 [6:07:00<4:42:10,  7.87s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Checkpoint saved to /workspace/qwen_checkpoints/step_2600\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4:  64%|   | 3672/5743 [6:15:15<3:03:37,  5.32s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 2610, Avg Loss: 3.1436\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4:  65%|   | 3752/5743 [6:23:57<2:46:37,  5.02s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 2620, Avg Loss: 4.0301\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4:  67%|   | 3832/5743 [6:32:11<3:53:58,  7.35s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 2630, Avg Loss: 2.8740\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4:  68%|   | 3912/5743 [6:40:14<3:08:36,  6.18s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 2640, Avg Loss: 2.0371\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4:  70%|   | 3992/5743 [6:48:19<2:36:35,  5.37s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 2650, Avg Loss: 2.6784\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4:  71%|   | 4072/5743 [6:56:15<2:42:40,  5.84s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 2660, Avg Loss: 2.8973\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4:  72%|  | 4152/5743 [7:04:08<2:29:38,  5.64s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 2670, Avg Loss: 2.6576\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4:  74%|  | 4232/5743 [7:12:08<2:50:54,  6.79s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 2680, Avg Loss: 2.1758\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4:  75%|  | 4312/5743 [7:20:05<2:07:54,  5.36s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 2690, Avg Loss: 2.2578\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4:  76%|  | 4392/5743 [7:28:16<2:41:08,  7.16s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 2700, Avg Loss: 2.4927\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4:  78%|  | 4472/5743 [7:36:23<2:20:16,  6.62s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 2710, Avg Loss: 2.0337\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4:  79%|  | 4552/5743 [7:44:27<2:35:38,  7.84s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 2720, Avg Loss: 1.9729\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4:  81%|  | 4632/5743 [7:52:40<2:09:29,  6.99s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 2730, Avg Loss: 2.5960\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4:  82%| | 4712/5743 [8:00:45<1:35:16,  5.54s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 2740, Avg Loss: 2.9128\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4:  83%| | 4792/5743 [8:09:03<1:38:13,  6.20s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 2750, Avg Loss: 2.8207\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4:  85%| | 4872/5743 [8:17:41<1:41:44,  7.01s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 2760, Avg Loss: 2.5432\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4:  86%| | 4952/5743 [8:25:51<1:12:41,  5.51s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 2770, Avg Loss: 2.7735\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4:  88%| | 5032/5743 [8:33:48<1:12:19,  6.10s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 2780, Avg Loss: 2.0866\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4:  89%| | 5112/5743 [8:42:00<1:14:44,  7.11s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 2790, Avg Loss: 2.8242\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4:  90%| | 5191/5743 [8:49:58<58:24,  6.35s/it]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 2800, Avg Loss: 2.6278\n",
            "\n",
            "Saving checkpoint at step 2800...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4:  90%| | 5192/5743 [8:50:22<1:45:32, 11.49s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Checkpoint saved to /workspace/qwen_checkpoints/step_2800\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4:  92%|| 5272/5743 [8:58:30<47:47,  6.09s/it]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 2810, Avg Loss: 2.4650\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4:  93%|| 5352/5743 [9:06:41<39:04,  6.00s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 2820, Avg Loss: 2.7118\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4:  95%|| 5432/5743 [9:15:06<32:38,  6.30s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 2830, Avg Loss: 1.9892\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4:  96%|| 5512/5743 [9:23:35<26:13,  6.81s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 2840, Avg Loss: 3.1756\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4:  97%|| 5592/5743 [9:31:42<15:36,  6.20s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 2850, Avg Loss: 2.1230\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4:  99%|| 5672/5743 [9:39:47<07:41,  6.50s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 2860, Avg Loss: 2.6935\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4: 100%|| 5743/5743 [9:47:32<00:00,  6.14s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Epoch 5/5 ===\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5:   0%|          | 16/5743 [01:31<10:04:29,  6.33s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 2870, Avg Loss: 2.5750\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5:   2%|         | 96/5743 [09:46<9:33:12,  6.09s/it] "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 2880, Avg Loss: 3.2225\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5:   3%|         | 176/5743 [18:12<11:39:29,  7.54s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 2890, Avg Loss: 2.5319\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5:   4%|         | 256/5743 [25:57<8:34:00,  5.62s/it] "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 2900, Avg Loss: 2.7188\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5:   6%|         | 336/5743 [34:10<9:42:36,  6.47s/it] "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 2910, Avg Loss: 2.7793\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5:   7%|         | 416/5743 [42:34<9:42:53,  6.57s/it] "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 2920, Avg Loss: 2.7346\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5:   9%|         | 496/5743 [50:51<8:38:56,  5.93s/it] "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 2930, Avg Loss: 2.1530\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5:  10%|         | 576/5743 [58:40<10:06:30,  7.04s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 2940, Avg Loss: 2.5168\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5:  11%|        | 656/5743 [1:06:29<7:47:06,  5.51s/it] "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 2950, Avg Loss: 2.8357\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5:  13%|        | 736/5743 [1:14:19<8:48:18,  6.33s/it] "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 2960, Avg Loss: 2.6985\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5:  14%|        | 816/5743 [1:22:33<8:45:41,  6.40s/it] "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 2970, Avg Loss: 2.6188\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5:  16%|        | 896/5743 [1:30:29<7:52:32,  5.85s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 2980, Avg Loss: 2.9717\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5:  17%|        | 976/5743 [1:38:31<7:55:41,  5.99s/it] "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 2990, Avg Loss: 2.7011\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5:  18%|        | 1055/5743 [1:46:50<8:00:26,  6.15s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 3000, Avg Loss: 2.7781\n",
            "\n",
            "Saving checkpoint at step 3000...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5:  18%|        | 1056/5743 [1:47:05<11:25:05,  8.77s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Checkpoint saved to /workspace/qwen_checkpoints/step_3000\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5:  20%|        | 1136/5743 [1:55:40<7:04:24,  5.53s/it] "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 3010, Avg Loss: 2.7730\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5:  21%|        | 1216/5743 [2:03:32<7:48:58,  6.22s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 3020, Avg Loss: 2.1680\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5:  23%|       | 1296/5743 [2:11:39<6:01:51,  4.88s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 3030, Avg Loss: 3.8665\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5:  24%|       | 1376/5743 [2:19:59<9:06:40,  7.51s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 3040, Avg Loss: 2.6330\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5:  25%|       | 1456/5743 [2:28:06<7:57:45,  6.69s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 3050, Avg Loss: 2.6153\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5:  27%|       | 1536/5743 [2:36:13<7:06:43,  6.09s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 3060, Avg Loss: 3.3306\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5:  28%|       | 1616/5743 [2:44:35<7:18:25,  6.37s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 3070, Avg Loss: 2.8937\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5:  30%|       | 1696/5743 [2:53:07<6:45:45,  6.02s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 3080, Avg Loss: 2.7724\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5:  31%|       | 1776/5743 [3:00:57<6:02:56,  5.49s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 3090, Avg Loss: 3.3607\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5:  32%|      | 1856/5743 [3:09:23<7:36:26,  7.05s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 3100, Avg Loss: 2.4959\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5:  34%|      | 1936/5743 [3:17:32<7:10:28,  6.78s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 3110, Avg Loss: 3.1827\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5:  35%|      | 2016/5743 [3:25:42<5:52:44,  5.68s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 3120, Avg Loss: 4.2266\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5:  36%|      | 2096/5743 [3:33:40<6:33:05,  6.47s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 3130, Avg Loss: 2.4336\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5:  38%|      | 2176/5743 [3:41:52<6:40:52,  6.74s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 3140, Avg Loss: 2.5099\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5:  39%|      | 2256/5743 [3:49:57<5:39:13,  5.84s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 3150, Avg Loss: 3.2688\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5:  41%|      | 2336/5743 [3:58:12<5:03:19,  5.34s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 3160, Avg Loss: 4.2138\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5:  42%|     | 2416/5743 [4:06:16<5:34:19,  6.03s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 3170, Avg Loss: 2.8885\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5:  43%|     | 2496/5743 [4:14:30<5:55:15,  6.56s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 3180, Avg Loss: 4.3390\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5:  45%|     | 2576/5743 [4:22:51<5:49:17,  6.62s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 3190, Avg Loss: 2.1370\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5:  46%|     | 2655/5743 [4:31:02<5:41:24,  6.63s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 3200, Avg Loss: 2.1022\n",
            "\n",
            "Saving checkpoint at step 3200...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5:  46%|     | 2656/5743 [4:31:19<8:31:33,  9.94s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Checkpoint saved to /workspace/qwen_checkpoints/step_3200\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5:  48%|     | 2736/5743 [4:39:58<6:14:45,  7.48s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 3210, Avg Loss: 2.1480\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5:  49%|     | 2816/5743 [4:48:44<5:46:53,  7.11s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 3220, Avg Loss: 2.3632\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5:  50%|     | 2896/5743 [4:56:35<3:49:06,  4.83s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 3230, Avg Loss: 3.5944\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5:  52%|    | 2976/5743 [5:04:19<4:23:49,  5.72s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 3240, Avg Loss: 2.5044\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5:  53%|    | 3056/5743 [5:12:39<5:17:40,  7.09s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 3250, Avg Loss: 2.8429\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5:  55%|    | 3136/5743 [5:20:48<3:31:11,  4.86s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 3260, Avg Loss: 5.0043\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5:  56%|    | 3216/5743 [5:29:03<4:27:48,  6.36s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 3270, Avg Loss: 2.5991\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5:  57%|    | 3296/5743 [5:37:23<5:06:59,  7.53s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 3280, Avg Loss: 2.6407\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5:  59%|    | 3376/5743 [5:45:08<4:11:52,  6.38s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 3290, Avg Loss: 2.8199\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5:  60%|    | 3456/5743 [5:53:06<3:12:38,  5.05s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 3300, Avg Loss: 2.8273\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5:  62%|   | 3536/5743 [6:01:00<3:23:07,  5.52s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 3310, Avg Loss: 3.6843\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5:  63%|   | 3616/5743 [6:09:12<3:14:30,  5.49s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 3320, Avg Loss: 3.9037\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5:  64%|   | 3696/5743 [6:18:00<3:18:11,  5.81s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 3330, Avg Loss: 2.6956\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5:  66%|   | 3776/5743 [6:26:21<3:04:56,  5.64s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 3340, Avg Loss: 3.0510\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5:  67%|   | 3856/5743 [6:34:48<3:39:47,  6.99s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 3350, Avg Loss: 2.9441\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5:  69%|   | 3936/5743 [6:43:10<3:22:51,  6.74s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 3360, Avg Loss: 3.0551\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5:  70%|   | 4016/5743 [6:51:08<2:52:44,  6.00s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 3370, Avg Loss: 2.5942\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5:  71%|  | 4096/5743 [6:59:12<3:01:27,  6.61s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 3380, Avg Loss: 2.4528\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5:  73%|  | 4176/5743 [7:07:15<2:30:27,  5.76s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 3390, Avg Loss: 2.4497\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5:  74%|  | 4255/5743 [7:15:06<2:03:49,  4.99s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 3400, Avg Loss: 3.9349\n",
            "\n",
            "Saving checkpoint at step 3400...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5:  74%|  | 4256/5743 [7:15:17<2:44:50,  6.65s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Checkpoint saved to /workspace/qwen_checkpoints/step_3400\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5:  76%|  | 4336/5743 [7:23:35<2:44:34,  7.02s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 3410, Avg Loss: 2.3985\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5:  77%|  | 4416/5743 [7:31:46<2:22:31,  6.44s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 3420, Avg Loss: 2.5839\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5:  78%|  | 4496/5743 [7:40:26<2:15:28,  6.52s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 3430, Avg Loss: 2.7224\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5:  80%|  | 4576/5743 [7:48:44<2:12:24,  6.81s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 3440, Avg Loss: 2.3408\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5:  81%|  | 4656/5743 [7:56:18<1:42:47,  5.67s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 3450, Avg Loss: 3.0145\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5:  82%| | 4736/5743 [8:04:47<1:55:55,  6.91s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 3460, Avg Loss: 2.3960\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5:  84%| | 4816/5743 [8:12:47<1:34:29,  6.12s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 3470, Avg Loss: 2.6005\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5:  85%| | 4896/5743 [8:20:50<1:20:39,  5.71s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 3480, Avg Loss: 2.9521\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5:  87%| | 4976/5743 [8:29:03<1:17:42,  6.08s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 3490, Avg Loss: 4.1878\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5:  88%| | 5056/5743 [8:37:21<57:11,  4.99s/it]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 3500, Avg Loss: 1.9959\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5:  89%| | 5136/5743 [8:45:44<1:17:41,  7.68s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 3510, Avg Loss: 2.2818\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5:  91%| | 5216/5743 [8:54:21<1:03:27,  7.23s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 3520, Avg Loss: 1.9451\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5:  92%|| 5296/5743 [9:02:22<40:49,  5.48s/it]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 3530, Avg Loss: 2.3365\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5:  94%|| 5376/5743 [9:10:28<46:27,  7.60s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 3540, Avg Loss: 2.5809\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5:  95%|| 5456/5743 [9:18:43<29:01,  6.07s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 3550, Avg Loss: 1.8184\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5:  96%|| 5536/5743 [9:26:19<19:46,  5.73s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 3560, Avg Loss: 2.5484\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5:  98%|| 5616/5743 [9:34:43<14:04,  6.65s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 3570, Avg Loss: 3.5725\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5:  99%|| 5696/5743 [9:42:52<04:45,  6.07s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 3580, Avg Loss: 2.7643\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5: 100%|| 5743/5743 [9:47:27<00:00,  6.14s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training finished.\n",
            "\n",
            "Saving final trained model to /workspace/mind2web_trained_model...\n",
            "Final model saved successfully.\n",
            " Zipping final model for download...\n",
            " Model zipped successfully: /workspace/mind2web_trained_model.zip\n",
            "Size: 0.08 GB\n",
            "\n",
            "To download this to your Mac, run the command below on YOUR LOCAL TERMINAL:\n",
            "scp -P [PORT] root@[IP_ADDRESS]:/workspace/mind2web_trained_model.zip ~/Downloads/\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import re\n",
        "from tqdm import tqdm\n",
        "from safetensors.torch import load_file\n",
        "\n",
        "checkpoint_dir = \"/workspace/qwen_checkpoints\"\n",
        "final_model_dir = \"/workspace/mind2web_trained_model\"\n",
        "os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "os.makedirs(final_model_dir, exist_ok=True)\n",
        "\n",
        "SAVE_EVERY_N_STEPS = 200\n",
        "\n",
        "latest_checkpoint_dir = None\n",
        "global_step = 0\n",
        "start_epoch = 0\n",
        "\n",
        "if os.path.exists(checkpoint_dir):\n",
        "    # Get all checkpoint directories (e.g., 'step_200', 'step_400')\n",
        "    step_dirs = [d for d in os.listdir(checkpoint_dir) if d.startswith('step_')]\n",
        "\n",
        "    if step_dirs:\n",
        "        # Find the step number from each directory name and get the max\n",
        "        latest_step = max([int(re.search(r'\\d+', d).group()) for d in step_dirs])\n",
        "        latest_checkpoint_dir = os.path.join(checkpoint_dir, f\"step_{latest_step}\")\n",
        "\n",
        "# --- LOAD FROM CHECKPOINT IF ONE WAS FOUND ---\n",
        "if latest_checkpoint_dir:\n",
        "    print(f\" Resuming training from the latest checkpoint: {latest_checkpoint_dir}\")\n",
        "\n",
        "    # Load the LoRA adapter weights\n",
        "    # strict=False is important as we are only loading the adapter, not the whole model\n",
        "    adapter_weights_path = os.path.join(latest_checkpoint_dir, \"adapter_model.safetensors\")\n",
        "    state_dict = load_file(adapter_weights_path)\n",
        "    model.load_state_dict(state_dict, strict=False)\n",
        "    print(\" Model adapter weights loaded successfully.\")\n",
        "\n",
        "    # 2. Check if the current optimizer is the one we want to use (AdamW8bit)\n",
        "    if isinstance(optimizer, bnb.optim.AdamW8bit):\n",
        "        try:\n",
        "            # Try to load the full checkpoint, including optimizer/scaler\n",
        "            checkpoint = torch.load(os.path.join(latest_checkpoint_dir, \"optimizer.pt\"))\n",
        "            optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "            scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
        "            scaler.load_state_dict(checkpoint['scaler_state_dict'])\n",
        "            print(\" Optimizer, scheduler, and scaler states loaded successfully.\")\n",
        "        except Exception as e:\n",
        "            # This will trigger on the first run after switching to AdamW8bit\n",
        "            print(f\" Could not load optimizer/scaler state. Starting fresh. This is expected.\")\n",
        "            print(f\"   Error details: {e}\")\n",
        "    else:\n",
        "        # If we're not using an 8-bit optimizer, just try to load optimizer/scheduler\n",
        "        try:\n",
        "            checkpoint = torch.load(os.path.join(latest_checkpoint_dir, \"optimizer.pt\"))\n",
        "            optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "            scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
        "            print(\" Optimizer and scheduler states loaded successfully (non-8bit).\")\n",
        "        except Exception as e:\n",
        "            print(f\" Could not load optimizer/scheduler state (non-8bit). Starting fresh. Error: {e}\")\n",
        "\n",
        "    # Restore the global step to continue numbering correctly\n",
        "    # We can parse it from the directory name for simplicity\n",
        "    global_step = latest_step\n",
        "    start_epoch = global_step * GRADIENT_ACCUM // len(loader)\n",
        "    print(f\"Resuming at global_step={global_step} (Epoch ~{start_epoch+1})\")\n",
        "\n",
        "else:\n",
        "    print(\"No checkpoint found. Starting training from scratch.\")\n",
        "\n",
        "model.train()\n",
        "\n",
        "for epoch in range(start_epoch, EPOCHS):\n",
        "    print(f\"\\n=== Epoch {epoch + 1}/{EPOCHS} ===\\n\")\n",
        "\n",
        "    if epoch == start_epoch:\n",
        "        steps_in_epoch_done = (global_step * GRADIENT_ACCUM) % len(loader)\n",
        "    else:\n",
        "        steps_in_epoch_done = 0\n",
        "\n",
        "    pbar = tqdm(enumerate(loader), total=len(loader), desc=f\"Epoch {epoch + 1}\")\n",
        "\n",
        "    for step, batch in pbar:\n",
        "\n",
        "        if step < steps_in_epoch_done:\n",
        "            continue\n",
        "\n",
        "        # Move batch to device\n",
        "        batch = {k: v.to(DEVICE) for k, v in batch.items()}\n",
        "        outputs = model(**batch, use_cache=False)\n",
        "        loss = outputs.loss / GRADIENT_ACCUM\n",
        "        scaler.scale(loss).backward()\n",
        "\n",
        "        # Gradient accumulation\n",
        "        if (step + 1) % GRADIENT_ACCUM == 0:\n",
        "            # Gradient clipping\n",
        "            scaler.unscale_(optimizer)\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), MAX_GRAD_NORM)\n",
        "\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "            optimizer.zero_grad()\n",
        "            scheduler.step()\n",
        "\n",
        "            global_step += 1\n",
        "\n",
        "            if global_step % 10 == 0:\n",
        "                running_loss = 0.0\n",
        "                print(f\"Step {global_step}, Avg Loss: {loss.item() * GRADIENT_ACCUM:.4f}\")\n",
        "\n",
        "            #Checkpoint saving logic\n",
        "            if global_step % SAVE_EVERY_N_STEPS == 0:\n",
        "                print(f\"\\nSaving checkpoint at step {global_step}...\")\n",
        "                step_checkpoint_dir = os.path.join(checkpoint_dir, f\"step_{global_step}\")\n",
        "                os.makedirs(step_checkpoint_dir, exist_ok=True)\n",
        "\n",
        "                # Save the PEFT model adapters\n",
        "                model.save_pretrained(step_checkpoint_dir)\n",
        "\n",
        "                # Save optimizer and other states\n",
        "                torch.save({\n",
        "                    'optimizer_state_dict': optimizer.state_dict(),\n",
        "                    'scheduler_state_dict': scheduler.state_dict(),\n",
        "                    'scaler_state_dict': scaler.state_dict()\n",
        "                }, os.path.join(step_checkpoint_dir, \"optimizer.pt\"))\n",
        "\n",
        "                print(f\"Checkpoint saved to {step_checkpoint_dir}\\n\")\n",
        "\n",
        "print(\"Training finished.\")\n",
        "\n",
        "print(f\"\\nSaving final trained model to {final_model_dir}...\")\n",
        "\n",
        "model.save_pretrained(final_model_dir)\n",
        "\n",
        "print(\"Final model saved successfully.\")\n",
        "\n",
        "\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "print(\" Zipping final model for download...\")\n",
        "\n",
        "# Output filename\n",
        "zip_name = \"mind2web_trained_model.zip\"\n",
        "zip_path = f\"/workspace/{zip_name}\"\n",
        "\n",
        "# Create the zip file\n",
        "# format: zip, root_dir: folder to zip\n",
        "shutil.make_archive(zip_path.replace('.zip', ''), 'zip', final_model_dir)\n",
        "\n",
        "print(f\" Model zipped successfully: {zip_path}\")\n",
        "print(f\"Size: {os.path.getsize(zip_path) / (1024*1024*1024):.2f} GB\")\n",
        "print(\"\\nTo download this to your Mac, run the command below on YOUR LOCAL TERMINAL:\")\n",
        "print(f\"scp -P [PORT] root@[IP_ADDRESS]:{zip_path} ~/Downloads/\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kBYYODmrzuqd",
        "outputId": "8e246f69-0fd4-4ad0-c4f8-c78230bbe829"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Zipping Checkpoints (This includes all steps, so it will be large)...\n",
            " Created: /workspace/all_checkpoints.zip\n",
            "\n",
            " Zipping Final Model...\n",
            " Created: /workspace/final_model.zip\n",
            "\n",
            " File Sizes:\n",
            "Checkpoints: 4.76 GB\n",
            "Final Model: 0.08 GB\n"
          ]
        }
      ],
      "source": [
        "import shutil\n",
        "import os\n",
        "\n",
        "# Define the source paths\n",
        "base_path = \"/workspace\"\n",
        "checkpoints_src = os.path.join(base_path, \"qwen_checkpoints\")\n",
        "model_src = os.path.join(base_path, \"mind2web_trained_model\")\n",
        "\n",
        "# Define the output names\n",
        "zip_1 = os.path.join(base_path, \"all_checkpoints\") # becomes all_checkpoints.zip\n",
        "zip_2 = os.path.join(base_path, \"final_model\")     # becomes final_model.zip\n",
        "\n",
        "print(\" Zipping Checkpoints (This includes all steps, so it will be large)...\")\n",
        "# format='zip', root_dir=folder_to_compress\n",
        "shutil.make_archive(zip_1, 'zip', checkpoints_src)\n",
        "print(f\" Created: {zip_1}.zip\")\n",
        "\n",
        "print(\"\\n Zipping Final Model...\")\n",
        "shutil.make_archive(zip_2, 'zip', model_src)\n",
        "print(f\" Created: {zip_2}.zip\")\n",
        "\n",
        "# Print sizes so you know what to expect\n",
        "size_1 = os.path.getsize(f\"{zip_1}.zip\") / (1024*1024*1024)\n",
        "size_2 = os.path.getsize(f\"{zip_2}.zip\") / (1024*1024*1024)\n",
        "\n",
        "print(f\"\\n File Sizes:\")\n",
        "print(f\"Checkpoints: {size_1:.2f} GB\")\n",
        "print(f\"Final Model: {size_2:.2f} GB\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Quick inference"
      ],
      "metadata": {
        "id": "Z3wd8Ya02Idq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "6bf8ada2cdbe40f98d9a3840d29ade9f",
            "399182ca98c24bf09878052234354f67",
            "e059b1b0f8a043b797c609e033d25cf0",
            "07195764f1c844fe8f57f8b3bbc8c915",
            "daee51865c7844c5b6deba2a6310507c",
            "4c88e66f9a85483384a3a7d947f2bbc0",
            "500bcaa6c1364d6b8dfa9ba7b3a94c3a",
            "f6ab29315aa44582b654ab460b0f78e7",
            "fc4b616948084cd5b8181c3872504be0",
            "5565cf210a4c4610abc0a0e83fda27dd",
            "f35988aeb5664f4f814095148bbff536",
            "6c15217aa5504fc083ec02d2e5e367f5"
          ]
        },
        "id": "PCPZcptu8cHY",
        "outputId": "507502ae-74e0-4db6-ff0f-691818ed5b73"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Loading Base Model...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6c15217aa5504fc083ec02d2e5e367f5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Loading Processor...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The image processor of type `Qwen2VLImageProcessor` is now loaded as a fast processor by default, even if the model checkpoint was saved with a slow processor. This is a breaking change and may produce slightly different outputs. To continue using the slow processor, instantiate this class with `use_fast=False`. Note that this behavior will be extended to all models in a future release.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Attaching LoRA Adapter...\n",
            " Model Ready for Inference!\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import AutoProcessor, Qwen2_5_VLForConditionalGeneration, BitsAndBytesConfig\n",
        "from peft import PeftModel\n",
        "from PIL import Image\n",
        "import json\n",
        "import os\n",
        "\n",
        "# 1. Define Paths\n",
        "# If on Colab, upload your unzipped 'final_model' folder to /content/final_model\n",
        "# If on RunPod, it's at /workspace/mind2web_trained_model\n",
        "ADAPTER_PATH = \"/workspace/mind2web_trained_model\" # Update this path!\n",
        "\n",
        "# 2. Load Base Model (4-bit to save memory)\n",
        "model_id = \"Qwen/Qwen2.5-VL-7B-Instruct\"\n",
        "\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16\n",
        ")\n",
        "\n",
        "print(\" Loading Base Model...\")\n",
        "base_model = Qwen2_5_VLForConditionalGeneration.from_pretrained(\n",
        "    model_id,\n",
        "    device_map=\"auto\",\n",
        "    quantization_config=bnb_config,\n",
        "    low_cpu_mem_usage=True\n",
        ")\n",
        "\n",
        "print(\" Loading Processor...\")\n",
        "processor = AutoProcessor.from_pretrained(model_id, trust_remote_code=True)\n",
        "\n",
        "# 3. Load Your Fine-Tuned LoRA Adapter\n",
        "print(\" Attaching LoRA Adapter...\")\n",
        "model = PeftModel.from_pretrained(base_model, ADAPTER_PATH)\n",
        "model.eval() # Set to inference mode\n",
        "\n",
        "print(\" Model Ready for Inference!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sLomiJjqzuqd"
      },
      "outputs": [],
      "source": [
        "def run_inference(sample, image_path):\n",
        "    # 1. Prepare Image (Apply the same Resize/Crop logic as training)\n",
        "    raw_image = Image.open(image_path).convert(\"RGB\")\n",
        "\n",
        "    # Resize Logic (Match your training script)\n",
        "    TARGET_WIDTH = 1024\n",
        "    MAX_HEIGHT = 1280\n",
        "    w_percent = (TARGET_WIDTH / float(raw_image.size[0]))\n",
        "    h_size = int((float(raw_image.size[1]) * float(w_percent)))\n",
        "\n",
        "    img_resized = raw_image.resize((TARGET_WIDTH, h_size), Image.LANCZOS)\n",
        "    if h_size > MAX_HEIGHT:\n",
        "        img_resized = img_resized.crop((0, 0, TARGET_WIDTH, MAX_HEIGHT))\n",
        "\n",
        "    # 2. Prepare Prompt\n",
        "    # We strip the \"System\" prompt structure because apply_chat_template handles it\n",
        "    # We just need the instruction text.\n",
        "\n",
        "    # Extract the raw instruction from your processed prompt\n",
        "    # Your prompt stored in JSONL usually looks like: \"You are a web agent...\\nTASK:...\"\n",
        "    # We can pass that directly.\n",
        "    prompt_text = sample['prompt']\n",
        "\n",
        "    messages = [\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": [\n",
        "                {\"type\": \"image\", \"image\": img_resized},\n",
        "                {\"type\": \"text\", \"text\": prompt_text},\n",
        "            ],\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    # 3. Process Inputs\n",
        "    text = processor.apply_chat_template(\n",
        "        messages, tokenize=False, add_generation_prompt=True\n",
        "    )\n",
        "\n",
        "    inputs = processor(\n",
        "        text=[text],\n",
        "        images=[img_resized],\n",
        "        padding=True,\n",
        "        return_tensors=\"pt\",\n",
        "    )\n",
        "    inputs = inputs.to(\"cuda\")\n",
        "\n",
        "    # 4. Generate\n",
        "    with torch.no_grad():\n",
        "        generated_ids = model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=128,  # JSON is usually short\n",
        "            do_sample=False,     # Greedy decoding (deterministic, best for code/json)\n",
        "            temperature=0.0      # Strict adherence\n",
        "        )\n",
        "\n",
        "    # 5. Decode\n",
        "    # Determine where the input ends and output begins\n",
        "    input_len = inputs.input_ids.shape[1]\n",
        "    generated_ids_trimmed = [\n",
        "        out_ids[input_len:] for out_ids in generated_ids\n",
        "    ]\n",
        "    output_text = processor.batch_decode(\n",
        "        generated_ids_trimmed, skip_special_tokens=True, clean_up_tokenization_spaces=False\n",
        "    )\n",
        "\n",
        "    return output_text[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KCO47Wrpzuqd",
        "outputId": "1b160412-d226-40f7-e76d-7123e41bf905"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Loading examples...\n",
            "\n",
            "================ EXAMPLE 1 ================\n",
            " TASK: View details for a Times Square parking lot that is wheelchair accessible.\n",
            " Image: 6b627cbc-a45e-4f7e-9d02-bfca1a41070a.jpeg\n",
            "\n",
            " MODEL PREDICTION:\n",
            "{\"action\": \"click\", \"element_id\": \"2149\", \"value\": \"\", \"is_finished\": false}\n",
            "\n",
            " GROUND TRUTH:\n",
            "{\"action\": \"click\", \"element_id\": \"2149\", \"value\": \"\", \"is_finished\": false}\n",
            "\n",
            "================ EXAMPLE 2 ================\n",
            " TASK: Find a parking lot in Gloucester and book a ride from there to North Plymouth on April 28, 2:30 pm, view the map to understand the route better.\n",
            " Image: 504c0c6b-7e78-4bfa-ae3f-00f8e59c3693.jpeg\n",
            "\n",
            " MODEL PREDICTION:\n",
            "{\"action\": \"click\", \"element_id\": \"101371\", \"value\": \"\", \"is_finished\": false}\n",
            "\n",
            " GROUND TRUTH:\n",
            "{\"action\": \"select\", \"element_id\": \"101373\", \"value\": \"PM\", \"is_finished\": false}\n",
            "\n",
            "================ EXAMPLE 3 ================\n",
            " TASK: Add 3 movies from At the Kiosk which are new to Wishlist.\n",
            " Image: c5871c3f-27c3-48d8-bdf9-8b49382a2719.jpeg\n",
            "\n",
            " MODEL PREDICTION:\n",
            "{\"action\": \"click\", \"element_id\": \"17194\", \"value\": \"\", \"is_finished\": false}\n",
            "\n",
            " GROUND TRUTH:\n",
            "{\"action\": \"click\", \"element_id\": \"None\", \"value\": \"\", \"is_finished\": false}\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import random\n",
        "\n",
        "# Path to your processed data\n",
        "JSONL_PATH = \"/workspace/mind2web_processed_train.jsonl\" # Update if needed\n",
        "# Path to your local images\n",
        "IMG_FOLDER = \"/workspace/m2w_i_local\" # Update if needed\n",
        "\n",
        "print(\" Loading examples...\")\n",
        "examples = []\n",
        "with open(JSONL_PATH, 'r') as f:\n",
        "    for line in f:\n",
        "        examples.append(json.loads(line))\n",
        "\n",
        "# Pick 3 random examples\n",
        "test_samples = random.sample(examples, 3)\n",
        "\n",
        "for i, sample in enumerate(test_samples):\n",
        "    print(f\"\\n================ EXAMPLE {i+1} ================\")\n",
        "\n",
        "    # Construct image path\n",
        "    img_filename = f\"{sample['annotation_id']}.jpeg\"\n",
        "    img_path = os.path.join(IMG_FOLDER, img_filename)\n",
        "\n",
        "    if not os.path.exists(img_path):\n",
        "        print(f\" Image missing: {img_path}\")\n",
        "        continue\n",
        "\n",
        "    print(f\" TASK: {sample['prompt'].split('TASK:')[1].split('ELEMENTS:')[0].strip()}\")\n",
        "    print(f\" Image: {img_filename}\")\n",
        "\n",
        "    try:\n",
        "        # Run Inference\n",
        "        prediction_str = run_inference(sample, img_path)\n",
        "\n",
        "        print(\"\\n MODEL PREDICTION:\")\n",
        "        print(prediction_str)\n",
        "\n",
        "        print(\"\\n GROUND TRUTH:\")\n",
        "        print(sample['label'])\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\" Error: {e}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "07195764f1c844fe8f57f8b3bbc8c915": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5565cf210a4c4610abc0a0e83fda27dd",
            "placeholder": "",
            "style": "IPY_MODEL_f35988aeb5664f4f814095148bbff536",
            "value": "5/5[00:05&lt;00:00,1.16it/s]"
          }
        },
        "08a2ee200f1a4ff2bd457c3b39214de0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6b0e214f070d4289b86f78c74d429dfa",
              "IPY_MODEL_33e4c16fb7014c70a8116928465fdf2d",
              "IPY_MODEL_3789283a2e9147e3ad478699c98e31e6"
            ],
            "layout": "IPY_MODEL_90c18d1a9c344ee28715cb02f93ce3d8"
          }
        },
        "08b642cc13e348438c1a32ae70dc2b6a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "14fd91cf7e8844548942bce8ae07fd25": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "20c98509cae045748a25e6c80100bcd8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "237c33efcc354dddabe7464b5f68f616": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "33e4c16fb7014c70a8116928465fdf2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a99a0a2b8fa749beb1e7d4b1b20cd810",
            "max": 27,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3bc89500c83341a09d26667c80a4dd79",
            "value": 27
          }
        },
        "3789283a2e9147e3ad478699c98e31e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_14fd91cf7e8844548942bce8ae07fd25",
            "placeholder": "",
            "style": "IPY_MODEL_237c33efcc354dddabe7464b5f68f616",
            "value": "27/27[00:00&lt;00:00,2416.13it/s]"
          }
        },
        "399182ca98c24bf09878052234354f67": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4c88e66f9a85483384a3a7d947f2bbc0",
            "placeholder": "",
            "style": "IPY_MODEL_500bcaa6c1364d6b8dfa9ba7b3a94c3a",
            "value": "Loadingcheckpointshards:100%"
          }
        },
        "3bc89500c83341a09d26667c80a4dd79": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4c88e66f9a85483384a3a7d947f2bbc0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "500bcaa6c1364d6b8dfa9ba7b3a94c3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "52ada261d08840edb5c0065c9bcfad01": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c3a1d4104aa94fe3b91f57562ecbf392",
            "placeholder": "",
            "style": "IPY_MODEL_20c98509cae045748a25e6c80100bcd8",
            "value": "5/5[00:18&lt;00:00,3.18s/it]"
          }
        },
        "5565cf210a4c4610abc0a0e83fda27dd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6a9d7bdd561f48bda617bafcc3aba715": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a208458b42de411a80390a6695063dc0",
            "placeholder": "",
            "style": "IPY_MODEL_abf09082f22e4d30a95e750977d98c74",
            "value": "Loadingcheckpointshards:100%"
          }
        },
        "6b0e214f070d4289b86f78c74d429dfa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9da29813b9e4417db6227244ccd79ca0",
            "placeholder": "",
            "style": "IPY_MODEL_f956d0508ebb47adb7c5a68e5919af00",
            "value": "Resolvingdatafiles:100%"
          }
        },
        "6bf8ada2cdbe40f98d9a3840d29ade9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_399182ca98c24bf09878052234354f67",
              "IPY_MODEL_e059b1b0f8a043b797c609e033d25cf0",
              "IPY_MODEL_07195764f1c844fe8f57f8b3bbc8c915"
            ],
            "layout": "IPY_MODEL_daee51865c7844c5b6deba2a6310507c"
          }
        },
        "90c18d1a9c344ee28715cb02f93ce3d8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9da29813b9e4417db6227244ccd79ca0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a208458b42de411a80390a6695063dc0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a99a0a2b8fa749beb1e7d4b1b20cd810": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "abf09082f22e4d30a95e750977d98c74": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b860bfcbaa314c2d99a4068043d907f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c3a1d4104aa94fe3b91f57562ecbf392": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c7d434f9db0a4801ab601b9b4b6cb288": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6a9d7bdd561f48bda617bafcc3aba715",
              "IPY_MODEL_d841bdcbc4b445d0a2c337ff6de0eb84",
              "IPY_MODEL_52ada261d08840edb5c0065c9bcfad01"
            ],
            "layout": "IPY_MODEL_e57e0e786fee4ec78a9366f0526ad3b0"
          }
        },
        "d841bdcbc4b445d0a2c337ff6de0eb84": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_08b642cc13e348438c1a32ae70dc2b6a",
            "max": 5,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b860bfcbaa314c2d99a4068043d907f3",
            "value": 5
          }
        },
        "daee51865c7844c5b6deba2a6310507c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e059b1b0f8a043b797c609e033d25cf0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f6ab29315aa44582b654ab460b0f78e7",
            "max": 5,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fc4b616948084cd5b8181c3872504be0",
            "value": 5
          }
        },
        "e57e0e786fee4ec78a9366f0526ad3b0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f35988aeb5664f4f814095148bbff536": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f6ab29315aa44582b654ab460b0f78e7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f956d0508ebb47adb7c5a68e5919af00": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fc4b616948084cd5b8181c3872504be0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}